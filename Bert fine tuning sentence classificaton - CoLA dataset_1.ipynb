{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bert fine tuning sentence classificaton - CoLA dataset_1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPfNlITmePQLS2Tj0Mgnffe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2sWKHnEPkGKN","executionInfo":{"status":"ok","timestamp":1638816666955,"user_tz":-330,"elapsed":1788,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"0e2e1d0b-916c-4c39-da10-5e5b149a4dc7"},"source":["import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","device_name"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YUZ6IQljqP5D","executionInfo":{"status":"ok","timestamp":1638816666956,"user_tz":-330,"elapsed":19,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"f90b0d6f-e0a8-4dee-96bf-40afd5de0f8b"},"source":["if device_name == '/device:GPU:0':\n","  print('Found GPU at: {}'.format(device_name))\n","else:\n","  raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"si1uanb7szWd","executionInfo":{"status":"ok","timestamp":1638816694619,"user_tz":-330,"elapsed":23107,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"65a507cd-d03e-4d25-e899-bddf8b33cfc5"},"source":["import torch\n","\n","if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","  print('We will use the GPU: {}'.format(torch.cuda.get_device_name()))\n","  print('We have {} GPU(s) available'.format(torch.cuda.device_count()))\n","else:\n","  device = torch.device('cpu')\n","  print('No GPU available, using CPU instead')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We will use the GPU: Tesla K80\n","We have 1 GPU(s) available\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tctNzS5pw3_q","executionInfo":{"status":"ok","timestamp":1638816737381,"user_tz":-330,"elapsed":8734,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"bc39e592-7b97-4238-d9f6-6bd969e01c49"},"source":["! pip install transformers\n","\n","# Get all possible models here: https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 35.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 41.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 527 kB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 37.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tZpfvlk9w8kb","executionInfo":{"status":"ok","timestamp":1638816748628,"user_tz":-330,"elapsed":9705,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"73f651eb-96eb-4618-e0ea-c34883765435"},"source":["! pip install wget"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=2d4378442f0a1a003806a93b828408973710a4c0b050a34de0e96149d9d98bc3\n","  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"]}]},{"cell_type":"code","metadata":{"id":"lED4HTN2ygqp"},"source":["# Download the file (if we haven't already)\n","\n","import wget\n","import os\n","\n","url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n","\n","if not os.path.exists('./cola_public_1.1.zip'):\n","  wget.download(url, './cola_public_1.1.zip')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51v__09l0jtL","executionInfo":{"status":"ok","timestamp":1638816749465,"user_tz":-330,"elapsed":32,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"2e8ddede-fc5e-47c3-9ef3-f6cbaa8396fb"},"source":["# Unzip the dataset\n","\n","if not os.path.exists('./cola_public/'):\n","  ! unzip cola_public_1.1.zip "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  cola_public_1.1.zip\n","   creating: cola_public/\n","  inflating: cola_public/README      \n","   creating: cola_public/tokenized/\n","  inflating: cola_public/tokenized/in_domain_dev.tsv  \n","  inflating: cola_public/tokenized/in_domain_train.tsv  \n","  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n","   creating: cola_public/raw/\n","  inflating: cola_public/raw/in_domain_dev.tsv  \n","  inflating: cola_public/raw/in_domain_train.tsv  \n","  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"yMzcL_dy3dGf","executionInfo":{"status":"ok","timestamp":1638816749466,"user_tz":-330,"elapsed":21,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"3aa1b603-8134-45db-8af2-7fe753d2b851"},"source":["import pandas as pd\n","\n","df = pd.read_csv('./cola_public/raw/in_domain_train.tsv', delimiter = '\\t', header = None, names = ['Sentence_source', 'Label', 'Label_notes', 'Sentence'])\n","print(df.shape)\n","df"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(8551, 4)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence_source</th>\n","      <th>Label</th>\n","      <th>Label_notes</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Our friends won't buy this analysis, let alone...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>One more pseudo generalization and I'm giving up.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>One more pseudo generalization or I'm giving up.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>The more we study verbs, the crazier they get.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Day by day the facts are getting murkier.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8546</th>\n","      <td>ad03</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>Poseidon appears to own a dragon</td>\n","    </tr>\n","    <tr>\n","      <th>8547</th>\n","      <td>ad03</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>Digitize is my happiest memory</td>\n","    </tr>\n","    <tr>\n","      <th>8548</th>\n","      <td>ad03</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>It is easy to slay the Gorgon.</td>\n","    </tr>\n","    <tr>\n","      <th>8549</th>\n","      <td>ad03</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>I had the strangest feeling that I knew you.</td>\n","    </tr>\n","    <tr>\n","      <th>8550</th>\n","      <td>ad03</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>What all did you get for Christmas?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8551 rows × 4 columns</p>\n","</div>"],"text/plain":["     Sentence_source  ...                                           Sentence\n","0               gj04  ...  Our friends won't buy this analysis, let alone...\n","1               gj04  ...  One more pseudo generalization and I'm giving up.\n","2               gj04  ...   One more pseudo generalization or I'm giving up.\n","3               gj04  ...     The more we study verbs, the crazier they get.\n","4               gj04  ...          Day by day the facts are getting murkier.\n","...              ...  ...                                                ...\n","8546            ad03  ...                   Poseidon appears to own a dragon\n","8547            ad03  ...                     Digitize is my happiest memory\n","8548            ad03  ...                     It is easy to slay the Gorgon.\n","8549            ad03  ...       I had the strangest feeling that I knew you.\n","8550            ad03  ...                What all did you get for Christmas?\n","\n","[8551 rows x 4 columns]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"HOfaughU73NH","executionInfo":{"status":"ok","timestamp":1638816749466,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"a0598d0e-14e6-492c-d01e-aa82c524651e"},"source":["df.loc[df.Label == 0].sample(5)[['Sentence', 'Label']]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5642</th>\n","      <td>The green loved peanut butter cookies.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3976</th>\n","      <td>Oliver drove me a lunatic.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7963</th>\n","      <td>There was he in the garden.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>934</th>\n","      <td>While Doc might claim that Bob had read his bo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3552</th>\n","      <td>He treats John very kind.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               Sentence  Label\n","5642             The green loved peanut butter cookies.      0\n","3976                         Oliver drove me a lunatic.      0\n","7963                        There was he in the garden.      0\n","934   While Doc might claim that Bob had read his bo...      0\n","3552                          He treats John very kind.      0"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"-PGDEFM79pOQ"},"source":["# Get the lists of sentences and their labels.\n","\n","sentences = df.Sentence.values\n","labels = df.Label.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["f17f1988a8fa4dd5bf0df260126e66e1","a3497dea809d4f8097886432306ac4df","0830eb51267249e1a55e850018518c0b","a48b7cb047ea45128cf3b5db133a2f52","391fa7dea6af4ffdb953edc47af070e0","4afbd43c8b6d4ac4bdcb3675ef97d573","aff1e2f69e3b4b2e816b4b7db57accef","2dfc467c1ba2469e9126e5278a5dd264","9fa38107174e46ef900b26f091022058","12bbd340017643e7a916e6a20b8638d9","f77bb2a375854c9e918b7374e2f9426c","f1ad7cc905be4b328b2911864168c283","ec72329d51b14bcfb4bbaff8e377c48f","cc6ae7cfb7a448ddbea160e8ac951b9b","af4c1d38349d49b88593fc9fe801416f","8a3346cfcf6c49a2ab96d723d206087a","1890d7f637604ddabb74862759949803","a721929b745a4b3280225c283c3de0df","34fb0c2dda91433f8bdd9c1cf690ff0a","fa508570a65f4d348e2b1e581e668bc2","fb773b294ee94e4e9c9f0ca96ff1074e","3897fdeea7324c46b6ac85f7528bdf68","6363930867664ec2903900b061b6ab42","be2c8f573ce2460c974e808deadd466e","3f1eedac06464292abc02adb5d66d184","793d12cc5dd241cb880003079ea8f773","63948d39b2714911912378f44eb553e7","08602dbdf90b4fb49507b256a70825b7","95c5a1e606b744af9e074da19a493010","ee257b4888f64bcbb8ca4ec5ae89ec1e","862f52b117924db4b0a895c01af2755c","7b81fa04b5044d6b85bb30a9e29385cc","31ecbb6a84d0401b8b2b0a59ce55f47e","5b1246f4750c4657b8e15ce6ce692aa2","be8a96e6a7824dc68da56e66f170b94b","83f47ac6f2af446ca63b5e777423f9fc","e006babef51f4676b59cf8499e001968","7f1aa27418614e178c162a18fb1cf62d","ec4e0900e63c4a17b6b32452f9fb4fd3","92f16bd52a884e41a089d356049b8d17","b83e8e19e4df42ea9341aa9c142af2cb","b62f86401dec4fddbf755a597a92491c","fecda7f2be604b86b1b71098bba102fa","39debebd6e4b418b902098a120e47b18"]},"id":"FbFM6y36-ccg","executionInfo":{"status":"ok","timestamp":1638816755678,"user_tz":-330,"elapsed":6225,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"4f768ef0-904f-463d-c3ad-e1cb4f36b5a4"},"source":["# Load the BERT Tokenizer\n","\n","from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f17f1988a8fa4dd5bf0df260126e66e1","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1ad7cc905be4b328b2911864168c283","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6363930867664ec2903900b061b6ab42","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b1246f4750c4657b8e15ce6ce692aa2","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F38ePeegGDaX","executionInfo":{"status":"ok","timestamp":1638816755678,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"e405b699-9000-4370-e838-a5c8f8defdb7"},"source":["print('Original: ', sentences[0])\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))\n","# We can tokenize and convert tokens to IDs by using encode"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  Our friends won't buy this analysis, let alone the next one we propose.\n","Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n","Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DzV4UoBGTlV","executionInfo":{"status":"ok","timestamp":1638816762729,"user_tz":-330,"elapsed":7061,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"b1836456-3bf6-456c-c7fa-b7565885aa6c"},"source":["max_len = 0\n","\n","for sent in sentences:\n","  input_ids = tokenizer.encode(sent, add_special_tokens = True)\n","  max_len = max(max_len, len(input_ids))\n","  \n","print('Maximum sentence length: ', max_len)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sentence length:  47\n"]}]},{"cell_type":"code","metadata":{"id":"VHoQzeEOGWDB"},"source":["# The tokenizer.encode_plus function combines multiple steps for us(First 4 are present in encode):\n","\n","# Split the sentence into tokens.\n","# Add the special [CLS] and [SEP] tokens.\n","# Map the tokens to their IDs.\n","# Pad or truncate all sentences to the same length.\n","# Create the attention masks which explicitly differentiate real tokens from [PAD] tokens."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpGrUUtbN-5O","executionInfo":{"status":"ok","timestamp":1638816773635,"user_tz":-330,"elapsed":983,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"ad4ee567-f284-4999-9fbd-c1423076ebe6"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","\n","input_ids = []\n","attention_masks = []\n","\n","for sent in sentences:\n","  encoded_dict = tokenizer.encode_plus(sent, add_special_tokens=True, max_length=64, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n","  input_ids.append(encoded_dict['input_ids'])\n","  attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0 now as a list of ids and attention mask\n","\n","print('Original: ', sentences[0])\n","print('Token IDs: ', input_ids[0])\n","print('Attention_mask: ', attention_masks[0])\n","print('Label: ', labels[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Original:  Our friends won't buy this analysis, let alone the next one we propose.\n","Token IDs:  tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n","         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0])\n","Attentin_mask:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","Label:  tensor(1)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2bYFEw3QV3R","executionInfo":{"status":"ok","timestamp":1638816785958,"user_tz":-330,"elapsed":12,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"de5ae686-6b80-4aa9-e73b-d23d1136921c"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90/10 train validation split\n","\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{} training samples'.format(train_size))\n","print('{} validation samples'.format(val_size))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7695 training samples\n","856 validation samples\n"]}]},{"cell_type":"code","metadata":{"id":"8WaCEARJSqNs"},"source":["# Create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because,\n","# unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory\n","\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 32\n","\n","train_dataloader = DataLoader(train_dataset, batch_size = batch_size, sampler = RandomSampler(train_dataset))\n","\n","validation_dataloader = DataLoader(val_dataset, batch_size = batch_size, sampler = SequentialSampler(val_dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["106d08d17d9d48579026c47ce2222f4d","d726ec9ecb364945aa6f15bad72c86f7","784e0642648c4b28b646d6165f276f30","7d2966469cfc4b3c9c557dc72226a599","d5a27709b1bf4309a3d07a1688a19dcd","210a01af25e34b20bbe8236057bfc612","e1926ce285ee4824b3c412130ac2faee","ee8ee7a8f38248ffa09eba9bd0ad4506","e3e505a1492843d381f31e019aa9da7f","a9605223bdf74315a7a944b727289eda","3cb6aee5d16d494895d6b5af46ae2690"]},"id":"KXBHiVXGi_Fr","executionInfo":{"status":"ok","timestamp":1638816808641,"user_tz":-330,"elapsed":18327,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"41de29c8-7d7c-4cc0-a82e-28f772dc01e8"},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, output_attentions=False, output_hidden_states=False)\n","\n","# Tell pytorch to run this model on GPU\n","\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"106d08d17d9d48579026c47ce2222f4d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"Nzx-PP-lmJ-f"},"source":["# Names and dimensions of the weights for the embedding layer, the first of the twelve transformers and the output layer."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SvRKgskuj2Qx","executionInfo":{"status":"ok","timestamp":1638816816007,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"e230ef0a-5a35-4a66-da8b-f24fca037016"},"source":["params = list(model.named_parameters())\n","print('The BERT model has {} different named parameters'.format(len(params)))\n","\n","# print('==== Embedding Layer ====\\n')\n","# for p in params[0:5]:\n","#   print(p[0], p[1].size())\n","\n","# print('\\n==== First Transformer ====\\n')\n","# for p in params[5:21]:\n","#   print(p[0], p[1].size())\n","\n","# print('\\n==== Output Layer ====\\n')\n","# for p in params[-4]:\n","#   print(p[0], p[1].size())\n","\n","print('==== Embedding Layer ====\\n')\n","for p in params[0:5]:\n","  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","for p in params[5:21]:\n","  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","for p in params[-4:]:\n","  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The BERT model has 201 different named parameters\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"]}]},{"cell_type":"code","metadata":{"id":"O8OUngbjlpsn"},"source":["# Grab the training hyperparameters from within the stored model\n","# Recommended: Batch size: 16, 32 || Learning rate (Adam): 5e-5, 3e-5, 2e-5 || Number of epochs: 2, 3, 4\n","# We chose: Batch size: 32 || Learning rate (Adam): 2e-5 || Number of epochs: 4\n","# The epsilon parameter eps = 1e-8 is \"a very small number to prevent any division by zero in the implementation\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktoYDo_Ap3_l","executionInfo":{"status":"ok","timestamp":1638816816007,"user_tz":-330,"elapsed":9,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"400096e1-8aac-490c-e1e5-bfbf465b9574"},"source":["model.parameters()  # These are all the weights and biases to be learned in the model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object Module.parameters at 0x7fe39f082ad0>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"ieqb20zLprIp"},"source":["# AdamW is Adam weight decay fix - imporvement from Adam\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","\n","# Default lr is 5e-5\n","# Default eps is 1e-8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tW-bLTz_zN9a"},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. We chose to run for 4, but we'll see later that this may be over-fitting the training data.\n","\n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create learning rate scheduler\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)  # num_warmup_steps=0 : Default value in run_glue.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uAI5YmJV0PVJ"},"source":["# Calculate accuracy of our predictions vs labels\n","\n","import numpy as np\n","\n","def flat_accuracy(preds, labels):\n","  pred_flat = np.argmax(preds, axis = 1).flatten()\n","  labels.flat = labels.flatten()\n","  return np.sum(pred_flat == labels.flat) / len(labels.flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Tj8HItEAq_Z","executionInfo":{"status":"ok","timestamp":1638816816009,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"5d96688c-0f03-4170-9007-e1ab3906e9fb"},"source":["iter(train_dataloader).next()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[  101,  2984,  3555,  ...,     0,     0,     0],\n","         [  101,  2296,  2879,  ...,     0,     0,     0],\n","         [  101,  1996,  1056,  ...,     0,     0,     0],\n","         ...,\n","         [  101,  2984, 10592,  ...,     0,     0,     0],\n","         [  101,  2070,  2040,  ...,     0,     0,     0],\n","         [  101, 21628,  2015,  ...,     0,     0,     0]]),\n"," tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]]),\n"," tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n","         1, 1, 0, 1, 0, 0, 0, 1])]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"0SRnl6Z5Jqnm"},"source":["import time\n","import datetime\n","  \n","def format_time(elapsed):\n","  '''\n","  Takes a time in seconds and returns a string hh:mm:ss\n","  '''\n","  # Round to the nearest second.\n","  elapsed_rounded = int(round((elapsed)))\n","  \n","  # Format as hh:mm:ss\n","  return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IWjsMfu_Jsm1","executionInfo":{"status":"ok","timestamp":1638817785890,"user_tz":-330,"elapsed":810,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"69ae78df-ab00-4cf5-f284-7004b56d2a6d"},"source":["time.time()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1638817784.9978404"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Hi2jX1h6yil","executionInfo":{"status":"ok","timestamp":1638821007174,"user_tz":-330,"elapsed":695777,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"e40b090f-6860-4430-d549-f213e3e41111"},"source":["import random\n","import numpy as np\n","import time\n","import torch\n","\n","# Set seed value for all values to reproduce the code\n","seed_value = 42\n","\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","torch.manual_seed(seed_value)\n","torch.cuda.manual_seed_all(seed_value)\n","\n","training_stats = []\n","total_t0 = time.time()\n","\n","for epoch in range(epochs):\n","\n","  print('Epoch {}'.format(epoch))\n","  t0 = time.time()\n","  total_train_loss = 0\n","\n","  model.train()   # Put the model into training mode - dropout` and `batchnorm` layers behave differently during training\n","  \n","  for step, batch in enumerate(train_dataloader):\n","\n","    # Progress update every 40 batches.\n","    if step % 40 == 0 and not step == 0:\n","        # Calculate elapsed time in minutes.\n","        elapsed = format_time(time.time() - t0)\n","        \n","        # Report progress.\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","    b_input_ids = batch[0].to(device)\n","    b_attention_masks = batch[1].to(device)\n","    b_labels = batch[2].to(device)\n","\n","    model.zero_grad()\n","\n","    result = model(b_input_ids, token_type_ids=None, attention_mask=b_attention_masks, labels=b_labels, return_dict=True)\n","    loss = result.loss\n","    logits = result.logits\n","    total_train_loss += loss.item()\n","\n","    loss.backward()\n","    \n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    optimizer.step()\n","\n","    scheduler.step()\n","\n","  avg_train_loss = total_train_loss / len(train_dataloader)\n","  print('Average training loss: {}'.format(avg_train_loss))\n","\n","  training_time = format_time(time.time() - t0)\n","  print('Training epoch {} took {}'.format(epoch, training_time))\n","\n","  print('Validation')\n","\n","  t0 = time.time()\n","\n","  model.eval()   # Put the model in evaluation mode--the dropout layers behave differently during evaluation\n","\n","  total_eval_accuracy = 0\n","  total_eval_loss = 0\n","  nb_eval_steps = 0\n","\n","  for step, batch in enumerate(validation_dataloader):\n","    print(step)\n","    print(batch)\n","    b_input_ids = batch[0].to(device)\n","    b_attention_masks = batch[1].to(device)\n","    b_labels = batch[2].to(device)\n","\n","    # Tell pytorch not to bother with constructing the compute graph during the forward pass, since this is only needed for backprop (training)\n","    with torch.no_grad():\n","      result = model(b_input_ids, token_type_ids=None, attention_mask=b_attention_masks, labels=b_labels, return_dict=True)\n","\n","    loss = result.loss\n","    logits = result.logits\n","\n","    total_eval_loss += loss.item()\n","    print('total_eval_loss')\n","    print(total_eval_loss)\n","\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    # calculate the accuracy for this batch of test sentences and accumulate it over all batches\n","    total_eval_accuracy += flat_accuracy(logits, label_ids)\n","    print('total_eval_accuracy')\n","    print(total_eval_accuracy)\n","\n","  avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","  print(len(validation_dataloader))\n","  print('Accuracy : {}'.format(avg_val_accuracy))\n","\n","  avg_val_loss = total_eval_loss/ len(validation_dataloader)\n","  validation_time = format_time(time.time() - t0)\n","  print('Validation loss: {}'.format(avg_val_loss))\n","  print('Validation epoch {} took {} time'.format(epoch, validation_time))\n","\n","  # Record all statistics from this epoch\n","  training_stats.append({'epoch': epoch+1, 'Training loss': avg_train_loss, 'Validation loss': avg_val_loss, 'Validation accuracy': avg_val_accuracy, 'Training time': training_time, 'Validation time': validation_time})\n","\n","print('Traning complete')\n","print('Total training took {} time'.format(format_time(time.time() - total_t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0\n","  Batch    40  of    241.    Elapsed: 0:00:28.\n","  Batch    80  of    241.    Elapsed: 0:00:56.\n","  Batch   120  of    241.    Elapsed: 0:01:24.\n","  Batch   160  of    241.    Elapsed: 0:01:51.\n","  Batch   200  of    241.    Elapsed: 0:02:19.\n","  Batch   240  of    241.    Elapsed: 0:02:47.\n","Average training loss: 0.06689792510491112\n","Training epoch 0 took 0:02:48\n","Validation\n","0\n","[tensor([[  101,  1045,  2404,  ...,     0,     0,     0],\n","        [  101, 15595,  3281,  ...,     0,     0,     0],\n","        [  101, 11296,  1005,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  2346,  ...,     0,     0,     0],\n","        [  101,  1045,  5763,  ...,     0,     0,     0],\n","        [  101,  1996,  4424,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n","        0, 1, 0, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","0.2752458155155182\n","total_eval_accuracy\n","0.90625\n","1\n","[tensor([[  101,  8836, 20323,  ...,     0,     0,     0],\n","        [  101,  2984,  3555,  ...,     0,     0,     0],\n","        [  101, 17081,  2001,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1045,  4687,  ...,     0,     0,     0],\n","        [  101,  2990,  2089,  ...,     0,     0,     0],\n","        [  101,  2040,  2003,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n","        0, 1, 1, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","1.027497798204422\n","total_eval_accuracy\n","1.75\n","2\n","[tensor([[  101,  8594,  7844,  ...,     0,     0,     0],\n","        [  101,  1045,  4797,  ...,     0,     0,     0],\n","        [  101, 12306,  2741,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  7427,  ...,     0,     0,     0],\n","        [  101, 12684,  5225,  ...,     0,     0,     0],\n","        [  101,  2129,  9191,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","        0, 0, 1, 0, 1, 0, 1, 0])]\n","total_eval_loss\n","1.9460502564907074\n","total_eval_accuracy\n","2.53125\n","3\n","[tensor([[ 101, 3419, 2699,  ...,    0,    0,    0],\n","        [ 101, 2040, 2106,  ...,    0,    0,    0],\n","        [ 101, 1045, 4565,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 1045, 2435,  ...,    0,    0,    0],\n","        [ 101, 6529, 2179,  ...,    0,    0,    0],\n","        [ 101, 2054, 2016,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","        1, 1, 1, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","3.345067948102951\n","total_eval_accuracy\n","3.28125\n","4\n","[tensor([[  101,  1996,  3663,  ...,     0,     0,     0],\n","        [  101,  2009,  2003,  ...,     0,     0,     0],\n","        [  101,  1996,  2879,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1045,  2113,  ...,     0,     0,     0],\n","        [  101, 14736, 11741,  ...,     0,     0,     0],\n","        [  101,  2057,  2228,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n","        0, 1, 1, 0, 1, 1, 1, 0])]\n","total_eval_loss\n","4.42183718085289\n","total_eval_accuracy\n","4.09375\n","5\n","[tensor([[  101,  2027,  2056,  ...,     0,     0,     0],\n","        [  101,  2151,  2879,  ...,     0,     0,     0],\n","        [  101,  2027,  6884,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 11271,  2003,  ...,     0,     0,     0],\n","        [  101,  1045,  2031,  ...,     0,     0,     0],\n","        [  101,  2198,  2134,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n","        1, 1, 1, 0, 1, 1, 0, 1])]\n","total_eval_loss\n","5.270726829767227\n","total_eval_accuracy\n","4.875\n","6\n","[tensor([[  101,  1996,  3482,  ...,     0,     0,     0],\n","        [  101, 13682,  2106,  ...,     0,     0,     0],\n","        [  101,  2984,  6369,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1037,  2338,  ...,     0,     0,     0],\n","        [  101,  1996,  9850,  ...,     0,     0,     0],\n","        [  101,  2057,  6476,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","        1, 0, 1, 0, 1, 0, 1, 0])]\n","total_eval_loss\n","6.293854981660843\n","total_eval_accuracy\n","5.71875\n","7\n","[tensor([[  101,  7673, 11308,  ...,     0,     0,     0],\n","        [  101,  1045,  2215,  ...,     0,     0,     0],\n","        [  101,  1045,  2175,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 15507,  1998,  ...,     0,     0,     0],\n","        [  101,  1996,  2879,  ...,     0,     0,     0],\n","        [  101,  5965,  3253,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","        1, 0, 0, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","6.705176264047623\n","total_eval_accuracy\n","6.625\n","8\n","[tensor([[  101,  1045,  2031,  ...,     0,     0,     0],\n","        [  101,  2027, 10847,  ...,     0,     0,     0],\n","        [  101,  2198,  2001,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  6947,  ...,     0,     0,     0],\n","        [  101,  2745,  4704,  ...,     0,     0,     0],\n","        [  101,  2065,  2198,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","6.979561060667038\n","total_eval_accuracy\n","7.53125\n","9\n","[tensor([[  101,  1996,  4268,  ...,     0,     0,     0],\n","        [  101,  1996, 14695,  ...,     0,     0,     0],\n","        [  101,  2002,  1005,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2984,  3373,  ...,     0,     0,     0],\n","        [  101,  2000,  5335,  ...,     0,     0,     0],\n","        [  101,  3419,  2743,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n","        1, 1, 1, 0, 1, 0, 1, 1])]\n","total_eval_loss\n","8.064705818891525\n","total_eval_accuracy\n","8.28125\n","10\n","[tensor([[  101,  1996,  3460,  ...,     0,     0,     0],\n","        [  101, 13382, 28201,  ...,     0,     0,     0],\n","        [  101,  1996,  1999,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  3869,  ...,     0,     0,     0],\n","        [  101,  2016,  2987,  ...,     0,     0,     0],\n","        [  101,  2471,  2296,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n","        1, 0, 0, 1, 0, 0, 0, 1])]\n","total_eval_loss\n","8.868690580129623\n","total_eval_accuracy\n","9.125\n","11\n","[tensor([[ 101, 2198, 5720,  ...,    0,    0,    0],\n","        [ 101, 2198, 5632,  ...,    0,    0,    0],\n","        [ 101, 2009, 2038,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 4463, 2001,  ...,    0,    0,    0],\n","        [ 101, 2984, 2003,  ...,    0,    0,    0],\n","        [ 101, 1996, 3482,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n","        0, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","9.543924897909164\n","total_eval_accuracy\n","10.0\n","12\n","[tensor([[ 101, 2027, 3236,  ...,    0,    0,    0],\n","        [ 101, 2016, 4025,  ...,    0,    0,    0],\n","        [ 101, 2087, 8626,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 1996, 2775,  ...,    0,    0,    0],\n","        [ 101, 2057, 2939,  ...,    0,    0,    0],\n","        [ 101, 2017, 2323,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 0, 1, 0, 1, 1, 1, 1])]\n","total_eval_loss\n","10.362362712621689\n","total_eval_accuracy\n","10.84375\n","13\n","[tensor([[  101,  1996,  2200,  ...,     0,     0,     0],\n","        [  101,  2014,  8114,  ...,     0,     0,     0],\n","        [  101,  2198,  6369,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2198,  6303,  ...,     0,     0,     0],\n","        [  101,  2040,  2079,  ...,     0,     0,     0],\n","        [  101,  2984, 11766,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","        0, 1, 1, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","10.677746087312698\n","total_eval_accuracy\n","11.78125\n","14\n","[tensor([[  101,  1045,  2741,  ...,     0,     0,     0],\n","        [  101,  2017,  2323,  ...,     0,     0,     0],\n","        [  101,  3021, 12984,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1999,  2394,  ...,     0,     0,     0],\n","        [  101,  1996,  6965,  ...,     0,     0,     0],\n","        [  101,  1045,  2387,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","11.11655017733574\n","total_eval_accuracy\n","12.625\n","15\n","[tensor([[  101,  1045,  2777,  ...,     0,     0,     0],\n","        [  101,  1996,  3608,  ...,     0,     0,     0],\n","        [  101,  2045, 29127,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2027,  2768,  ...,     0,     0,     0],\n","        [  101,  1045,  1005,  ...,     0,     0,     0],\n","        [  101,  1037,  2338,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n","        0, 0, 0, 1, 1, 1, 0, 1])]\n","total_eval_loss\n","11.906878143548965\n","total_eval_accuracy\n","13.46875\n","16\n","[tensor([[  101,  2017,  2064,  ...,     0,     0,     0],\n","        [  101,  1996,  2450,  ...,     0,     0,     0],\n","        [  101,  2023,  6045,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  2711,  ...,     0,     0,     0],\n","        [  101,  1996, 12779,  ...,     0,     0,     0],\n","        [  101,  1996,  2711,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n","        0, 0, 0, 1, 1, 0, 0, 1])]\n","total_eval_loss\n","12.771537154912949\n","total_eval_accuracy\n","14.28125\n","17\n","[tensor([[  101, 15507,  5292,  ...,     0,     0,     0],\n","        [  101,  3071,  3230,  ...,     0,     0,     0],\n","        [  101,  2006,  2029,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2829,  6055,  ...,     0,     0,     0],\n","        [  101,  2002,  8871,  ...,     0,     0,     0],\n","        [  101,  1996, 15034,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n","        1, 1, 0, 0, 0, 0, 0, 1])]\n","total_eval_loss\n","13.87933561205864\n","total_eval_accuracy\n","15.0625\n","18\n","[tensor([[  101,  2040,  2106,  ...,     0,     0,     0],\n","        [  101,  1996,  2417,  ...,     0,     0,     0],\n","        [  101, 19431,  2768,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2016,  2467,  ...,     0,     0,     0],\n","        [  101,  1045,  2097,  ...,     0,     0,     0],\n","        [  101,  2296,  3076,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","        0, 1, 1, 1, 1, 0, 1, 0])]\n","total_eval_loss\n","14.598445922136307\n","total_eval_accuracy\n","15.90625\n","19\n","[tensor([[  101,  2198,  2699,  ...,     0,     0,     0],\n","        [  101,  1996,  4049,  ...,     0,     0,     0],\n","        [  101, 11130,  2018,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2009,  2318,  ...,     0,     0,     0],\n","        [  101,  1996,  4944,  ...,     0,     0,     0],\n","        [  101,  5545,  3013,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n","        1, 0, 1, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","15.080131202936172\n","total_eval_accuracy\n","16.8125\n","20\n","[tensor([[  101,  3071,  8069,  ...,     0,     0,     0],\n","        [  101,  1045,  2066,  ...,     0,     0,     0],\n","        [  101,  8808, 12328,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  4572,  2741,  ...,     0,     0,     0],\n","        [  101,  1996,  3043,  ...,     0,     0,     0],\n","        [  101,  2045,  2145,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n","        1, 0, 1, 0, 0, 1, 1, 1])]\n","total_eval_loss\n","16.679427057504654\n","total_eval_accuracy\n","17.5\n","21\n","[tensor([[  101,  2198,  7164,  ...,     0,     0,     0],\n","        [  101,  2984,  2038,  ...,     0,     0,     0],\n","        [  101,  1045,  2387,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  3021,  2187,  ...,     0,     0,     0],\n","        [  101,  2031,  2017,  ...,     0,     0,     0],\n","        [  101,  1996, 14829,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n","        0, 0, 1, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","17.775981336832047\n","total_eval_accuracy\n","18.28125\n","22\n","[tensor([[ 101, 1037, 2158,  ...,    0,    0,    0],\n","        [ 101, 2027, 3191,  ...,    0,    0,    0],\n","        [ 101, 1045, 2031,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 8472, 8823,  ...,    0,    0,    0],\n","        [ 101, 1045, 1005,  ...,    0,    0,    0],\n","        [ 101, 1999, 2029,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n","        1, 0, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","18.188112676143646\n","total_eval_accuracy\n","19.21875\n","23\n","[tensor([[ 101, 2043, 2984,  ...,    0,    0,    0],\n","        [ 101, 2984, 6369,  ...,    0,    0,    0],\n","        [ 101, 5909, 2718,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 2009, 2001,  ...,    0,    0,    0],\n","        [ 101, 1996, 2332,  ...,    0,    0,    0],\n","        [ 101, 2040, 2106,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n","        1, 1, 1, 1, 0, 1, 1, 0])]\n","total_eval_loss\n","18.776611268520355\n","total_eval_accuracy\n","20.125\n","24\n","[tensor([[  101,  1045,  2052,  ...,     0,     0,     0],\n","        [  101,  6986,  4375,  ...,     0,     0,     0],\n","        [  101,  4116,  3631,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 15809, 14163,  ...,     0,     0,     0],\n","        [  101,  2057,  2031,  ...,     0,     0,     0],\n","        [  101,  4463,  3832,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n","        1, 1, 0, 1, 0, 0, 1, 0])]\n","total_eval_loss\n","19.313508927822113\n","total_eval_accuracy\n","21.03125\n","25\n","[tensor([[  101,  2002,  2939,  ...,     0,     0,     0],\n","        [  101,  2122, 17304,  ...,     0,     0,     0],\n","        [  101,  2079,  2025,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 12943, 14074,  ...,     0,     0,     0],\n","        [  101,  2054,  2016,  ...,     0,     0,     0],\n","        [  101,  2008,  3520,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n","        1, 1, 0, 1, 1, 1, 0, 0])]\n","total_eval_loss\n","20.1870499253273\n","total_eval_accuracy\n","21.84375\n","26\n","[tensor([[  101,  2984,  1005,  ...,     0,     0,     0],\n","        [  101,  1045,  2064,  ...,     0,     0,     0],\n","        [  101, 10508, 11248,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2070, 11746,  ...,     0,     0,     0],\n","        [  101, 10654, 15608,  ...,     0,     0,     0],\n","        [  101,  2984,  3248,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","20.639140188694\n","total_eval_accuracy\n","22.71875\n","27\n","Accuracy : 0.8414351851851852\n","Validation loss: 0.7644125995812593\n","Validation epoch 0 took 0:00:07 time\n","Epoch 1\n","  Batch    40  of    241.    Elapsed: 0:00:28.\n","  Batch    80  of    241.    Elapsed: 0:00:56.\n","  Batch   120  of    241.    Elapsed: 0:01:23.\n","  Batch   160  of    241.    Elapsed: 0:01:51.\n","  Batch   200  of    241.    Elapsed: 0:02:19.\n","  Batch   240  of    241.    Elapsed: 0:02:47.\n","Average training loss: 0.29765367364564993\n","Training epoch 1 took 0:02:47\n","Validation\n","0\n","[tensor([[  101,  1045,  2404,  ...,     0,     0,     0],\n","        [  101, 15595,  3281,  ...,     0,     0,     0],\n","        [  101, 11296,  1005,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  2346,  ...,     0,     0,     0],\n","        [  101,  1045,  5763,  ...,     0,     0,     0],\n","        [  101,  1996,  4424,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n","        0, 1, 0, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","0.2752458155155182\n","total_eval_accuracy\n","0.90625\n","1\n","[tensor([[  101,  8836, 20323,  ...,     0,     0,     0],\n","        [  101,  2984,  3555,  ...,     0,     0,     0],\n","        [  101, 17081,  2001,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1045,  4687,  ...,     0,     0,     0],\n","        [  101,  2990,  2089,  ...,     0,     0,     0],\n","        [  101,  2040,  2003,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n","        0, 1, 1, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","1.027497798204422\n","total_eval_accuracy\n","1.75\n","2\n","[tensor([[  101,  8594,  7844,  ...,     0,     0,     0],\n","        [  101,  1045,  4797,  ...,     0,     0,     0],\n","        [  101, 12306,  2741,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  7427,  ...,     0,     0,     0],\n","        [  101, 12684,  5225,  ...,     0,     0,     0],\n","        [  101,  2129,  9191,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","        0, 0, 1, 0, 1, 0, 1, 0])]\n","total_eval_loss\n","1.9460502564907074\n","total_eval_accuracy\n","2.53125\n","3\n","[tensor([[ 101, 3419, 2699,  ...,    0,    0,    0],\n","        [ 101, 2040, 2106,  ...,    0,    0,    0],\n","        [ 101, 1045, 4565,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 1045, 2435,  ...,    0,    0,    0],\n","        [ 101, 6529, 2179,  ...,    0,    0,    0],\n","        [ 101, 2054, 2016,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","        1, 1, 1, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","3.345067948102951\n","total_eval_accuracy\n","3.28125\n","4\n","[tensor([[  101,  1996,  3663,  ...,     0,     0,     0],\n","        [  101,  2009,  2003,  ...,     0,     0,     0],\n","        [  101,  1996,  2879,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1045,  2113,  ...,     0,     0,     0],\n","        [  101, 14736, 11741,  ...,     0,     0,     0],\n","        [  101,  2057,  2228,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n","        0, 1, 1, 0, 1, 1, 1, 0])]\n","total_eval_loss\n","4.42183718085289\n","total_eval_accuracy\n","4.09375\n","5\n","[tensor([[  101,  2027,  2056,  ...,     0,     0,     0],\n","        [  101,  2151,  2879,  ...,     0,     0,     0],\n","        [  101,  2027,  6884,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 11271,  2003,  ...,     0,     0,     0],\n","        [  101,  1045,  2031,  ...,     0,     0,     0],\n","        [  101,  2198,  2134,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n","        1, 1, 1, 0, 1, 1, 0, 1])]\n","total_eval_loss\n","5.270726829767227\n","total_eval_accuracy\n","4.875\n","6\n","[tensor([[  101,  1996,  3482,  ...,     0,     0,     0],\n","        [  101, 13682,  2106,  ...,     0,     0,     0],\n","        [  101,  2984,  6369,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1037,  2338,  ...,     0,     0,     0],\n","        [  101,  1996,  9850,  ...,     0,     0,     0],\n","        [  101,  2057,  6476,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","        1, 0, 1, 0, 1, 0, 1, 0])]\n","total_eval_loss\n","6.293854981660843\n","total_eval_accuracy\n","5.71875\n","7\n","[tensor([[  101,  7673, 11308,  ...,     0,     0,     0],\n","        [  101,  1045,  2215,  ...,     0,     0,     0],\n","        [  101,  1045,  2175,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 15507,  1998,  ...,     0,     0,     0],\n","        [  101,  1996,  2879,  ...,     0,     0,     0],\n","        [  101,  5965,  3253,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","        1, 0, 0, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","6.705176264047623\n","total_eval_accuracy\n","6.625\n","8\n","[tensor([[  101,  1045,  2031,  ...,     0,     0,     0],\n","        [  101,  2027, 10847,  ...,     0,     0,     0],\n","        [  101,  2198,  2001,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  6947,  ...,     0,     0,     0],\n","        [  101,  2745,  4704,  ...,     0,     0,     0],\n","        [  101,  2065,  2198,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","6.979561060667038\n","total_eval_accuracy\n","7.53125\n","9\n","[tensor([[  101,  1996,  4268,  ...,     0,     0,     0],\n","        [  101,  1996, 14695,  ...,     0,     0,     0],\n","        [  101,  2002,  1005,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2984,  3373,  ...,     0,     0,     0],\n","        [  101,  2000,  5335,  ...,     0,     0,     0],\n","        [  101,  3419,  2743,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n","        1, 1, 1, 0, 1, 0, 1, 1])]\n","total_eval_loss\n","8.064705818891525\n","total_eval_accuracy\n","8.28125\n","10\n","[tensor([[  101,  1996,  3460,  ...,     0,     0,     0],\n","        [  101, 13382, 28201,  ...,     0,     0,     0],\n","        [  101,  1996,  1999,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  3869,  ...,     0,     0,     0],\n","        [  101,  2016,  2987,  ...,     0,     0,     0],\n","        [  101,  2471,  2296,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n","        1, 0, 0, 1, 0, 0, 0, 1])]\n","total_eval_loss\n","8.868690580129623\n","total_eval_accuracy\n","9.125\n","11\n","[tensor([[ 101, 2198, 5720,  ...,    0,    0,    0],\n","        [ 101, 2198, 5632,  ...,    0,    0,    0],\n","        [ 101, 2009, 2038,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 4463, 2001,  ...,    0,    0,    0],\n","        [ 101, 2984, 2003,  ...,    0,    0,    0],\n","        [ 101, 1996, 3482,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n","        0, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","9.543924897909164\n","total_eval_accuracy\n","10.0\n","12\n","[tensor([[ 101, 2027, 3236,  ...,    0,    0,    0],\n","        [ 101, 2016, 4025,  ...,    0,    0,    0],\n","        [ 101, 2087, 8626,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 1996, 2775,  ...,    0,    0,    0],\n","        [ 101, 2057, 2939,  ...,    0,    0,    0],\n","        [ 101, 2017, 2323,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 0, 1, 0, 1, 1, 1, 1])]\n","total_eval_loss\n","10.362362712621689\n","total_eval_accuracy\n","10.84375\n","13\n","[tensor([[  101,  1996,  2200,  ...,     0,     0,     0],\n","        [  101,  2014,  8114,  ...,     0,     0,     0],\n","        [  101,  2198,  6369,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2198,  6303,  ...,     0,     0,     0],\n","        [  101,  2040,  2079,  ...,     0,     0,     0],\n","        [  101,  2984, 11766,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","        0, 1, 1, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","10.677746087312698\n","total_eval_accuracy\n","11.78125\n","14\n","[tensor([[  101,  1045,  2741,  ...,     0,     0,     0],\n","        [  101,  2017,  2323,  ...,     0,     0,     0],\n","        [  101,  3021, 12984,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1999,  2394,  ...,     0,     0,     0],\n","        [  101,  1996,  6965,  ...,     0,     0,     0],\n","        [  101,  1045,  2387,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","11.11655017733574\n","total_eval_accuracy\n","12.625\n","15\n","[tensor([[  101,  1045,  2777,  ...,     0,     0,     0],\n","        [  101,  1996,  3608,  ...,     0,     0,     0],\n","        [  101,  2045, 29127,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2027,  2768,  ...,     0,     0,     0],\n","        [  101,  1045,  1005,  ...,     0,     0,     0],\n","        [  101,  1037,  2338,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n","        0, 0, 0, 1, 1, 1, 0, 1])]\n","total_eval_loss\n","11.906878143548965\n","total_eval_accuracy\n","13.46875\n","16\n","[tensor([[  101,  2017,  2064,  ...,     0,     0,     0],\n","        [  101,  1996,  2450,  ...,     0,     0,     0],\n","        [  101,  2023,  6045,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  2711,  ...,     0,     0,     0],\n","        [  101,  1996, 12779,  ...,     0,     0,     0],\n","        [  101,  1996,  2711,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n","        0, 0, 0, 1, 1, 0, 0, 1])]\n","total_eval_loss\n","12.771537154912949\n","total_eval_accuracy\n","14.28125\n","17\n","[tensor([[  101, 15507,  5292,  ...,     0,     0,     0],\n","        [  101,  3071,  3230,  ...,     0,     0,     0],\n","        [  101,  2006,  2029,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2829,  6055,  ...,     0,     0,     0],\n","        [  101,  2002,  8871,  ...,     0,     0,     0],\n","        [  101,  1996, 15034,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n","        1, 1, 0, 0, 0, 0, 0, 1])]\n","total_eval_loss\n","13.87933561205864\n","total_eval_accuracy\n","15.0625\n","18\n","[tensor([[  101,  2040,  2106,  ...,     0,     0,     0],\n","        [  101,  1996,  2417,  ...,     0,     0,     0],\n","        [  101, 19431,  2768,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2016,  2467,  ...,     0,     0,     0],\n","        [  101,  1045,  2097,  ...,     0,     0,     0],\n","        [  101,  2296,  3076,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","        0, 1, 1, 1, 1, 0, 1, 0])]\n","total_eval_loss\n","14.598445922136307\n","total_eval_accuracy\n","15.90625\n","19\n","[tensor([[  101,  2198,  2699,  ...,     0,     0,     0],\n","        [  101,  1996,  4049,  ...,     0,     0,     0],\n","        [  101, 11130,  2018,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2009,  2318,  ...,     0,     0,     0],\n","        [  101,  1996,  4944,  ...,     0,     0,     0],\n","        [  101,  5545,  3013,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n","        1, 0, 1, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","15.080131202936172\n","total_eval_accuracy\n","16.8125\n","20\n","[tensor([[  101,  3071,  8069,  ...,     0,     0,     0],\n","        [  101,  1045,  2066,  ...,     0,     0,     0],\n","        [  101,  8808, 12328,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  4572,  2741,  ...,     0,     0,     0],\n","        [  101,  1996,  3043,  ...,     0,     0,     0],\n","        [  101,  2045,  2145,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n","        1, 0, 1, 0, 0, 1, 1, 1])]\n","total_eval_loss\n","16.679427057504654\n","total_eval_accuracy\n","17.5\n","21\n","[tensor([[  101,  2198,  7164,  ...,     0,     0,     0],\n","        [  101,  2984,  2038,  ...,     0,     0,     0],\n","        [  101,  1045,  2387,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  3021,  2187,  ...,     0,     0,     0],\n","        [  101,  2031,  2017,  ...,     0,     0,     0],\n","        [  101,  1996, 14829,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n","        0, 0, 1, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","17.775981336832047\n","total_eval_accuracy\n","18.28125\n","22\n","[tensor([[ 101, 1037, 2158,  ...,    0,    0,    0],\n","        [ 101, 2027, 3191,  ...,    0,    0,    0],\n","        [ 101, 1045, 2031,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 8472, 8823,  ...,    0,    0,    0],\n","        [ 101, 1045, 1005,  ...,    0,    0,    0],\n","        [ 101, 1999, 2029,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n","        1, 0, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","18.188112676143646\n","total_eval_accuracy\n","19.21875\n","23\n","[tensor([[ 101, 2043, 2984,  ...,    0,    0,    0],\n","        [ 101, 2984, 6369,  ...,    0,    0,    0],\n","        [ 101, 5909, 2718,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 2009, 2001,  ...,    0,    0,    0],\n","        [ 101, 1996, 2332,  ...,    0,    0,    0],\n","        [ 101, 2040, 2106,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n","        1, 1, 1, 1, 0, 1, 1, 0])]\n","total_eval_loss\n","18.776611268520355\n","total_eval_accuracy\n","20.125\n","24\n","[tensor([[  101,  1045,  2052,  ...,     0,     0,     0],\n","        [  101,  6986,  4375,  ...,     0,     0,     0],\n","        [  101,  4116,  3631,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 15809, 14163,  ...,     0,     0,     0],\n","        [  101,  2057,  2031,  ...,     0,     0,     0],\n","        [  101,  4463,  3832,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n","        1, 1, 0, 1, 0, 0, 1, 0])]\n","total_eval_loss\n","19.313508927822113\n","total_eval_accuracy\n","21.03125\n","25\n","[tensor([[  101,  2002,  2939,  ...,     0,     0,     0],\n","        [  101,  2122, 17304,  ...,     0,     0,     0],\n","        [  101,  2079,  2025,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 12943, 14074,  ...,     0,     0,     0],\n","        [  101,  2054,  2016,  ...,     0,     0,     0],\n","        [  101,  2008,  3520,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n","        1, 1, 0, 1, 1, 1, 0, 0])]\n","total_eval_loss\n","20.1870499253273\n","total_eval_accuracy\n","21.84375\n","26\n","[tensor([[  101,  2984,  1005,  ...,     0,     0,     0],\n","        [  101,  1045,  2064,  ...,     0,     0,     0],\n","        [  101, 10508, 11248,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2070, 11746,  ...,     0,     0,     0],\n","        [  101, 10654, 15608,  ...,     0,     0,     0],\n","        [  101,  2984,  3248,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","20.639140188694\n","total_eval_accuracy\n","22.71875\n","27\n","Accuracy : 0.8414351851851852\n","Validation loss: 0.7644125995812593\n","Validation epoch 1 took 0:00:07 time\n","Epoch 2\n","  Batch    40  of    241.    Elapsed: 0:00:28.\n","  Batch    80  of    241.    Elapsed: 0:00:56.\n","  Batch   120  of    241.    Elapsed: 0:01:23.\n","  Batch   160  of    241.    Elapsed: 0:01:51.\n","  Batch   200  of    241.    Elapsed: 0:02:19.\n","  Batch   240  of    241.    Elapsed: 0:02:47.\n","Average training loss: 0.2932015156307687\n","Training epoch 2 took 0:02:47\n","Validation\n","0\n","[tensor([[  101,  1045,  2404,  ...,     0,     0,     0],\n","        [  101, 15595,  3281,  ...,     0,     0,     0],\n","        [  101, 11296,  1005,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  2346,  ...,     0,     0,     0],\n","        [  101,  1045,  5763,  ...,     0,     0,     0],\n","        [  101,  1996,  4424,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n","        0, 1, 0, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","0.2752458155155182\n","total_eval_accuracy\n","0.90625\n","1\n","[tensor([[  101,  8836, 20323,  ...,     0,     0,     0],\n","        [  101,  2984,  3555,  ...,     0,     0,     0],\n","        [  101, 17081,  2001,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1045,  4687,  ...,     0,     0,     0],\n","        [  101,  2990,  2089,  ...,     0,     0,     0],\n","        [  101,  2040,  2003,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n","        0, 1, 1, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","1.027497798204422\n","total_eval_accuracy\n","1.75\n","2\n","[tensor([[  101,  8594,  7844,  ...,     0,     0,     0],\n","        [  101,  1045,  4797,  ...,     0,     0,     0],\n","        [  101, 12306,  2741,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  7427,  ...,     0,     0,     0],\n","        [  101, 12684,  5225,  ...,     0,     0,     0],\n","        [  101,  2129,  9191,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","        0, 0, 1, 0, 1, 0, 1, 0])]\n","total_eval_loss\n","1.9460502564907074\n","total_eval_accuracy\n","2.53125\n","3\n","[tensor([[ 101, 3419, 2699,  ...,    0,    0,    0],\n","        [ 101, 2040, 2106,  ...,    0,    0,    0],\n","        [ 101, 1045, 4565,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 1045, 2435,  ...,    0,    0,    0],\n","        [ 101, 6529, 2179,  ...,    0,    0,    0],\n","        [ 101, 2054, 2016,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","        1, 1, 1, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","3.345067948102951\n","total_eval_accuracy\n","3.28125\n","4\n","[tensor([[  101,  1996,  3663,  ...,     0,     0,     0],\n","        [  101,  2009,  2003,  ...,     0,     0,     0],\n","        [  101,  1996,  2879,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1045,  2113,  ...,     0,     0,     0],\n","        [  101, 14736, 11741,  ...,     0,     0,     0],\n","        [  101,  2057,  2228,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n","        0, 1, 1, 0, 1, 1, 1, 0])]\n","total_eval_loss\n","4.42183718085289\n","total_eval_accuracy\n","4.09375\n","5\n","[tensor([[  101,  2027,  2056,  ...,     0,     0,     0],\n","        [  101,  2151,  2879,  ...,     0,     0,     0],\n","        [  101,  2027,  6884,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 11271,  2003,  ...,     0,     0,     0],\n","        [  101,  1045,  2031,  ...,     0,     0,     0],\n","        [  101,  2198,  2134,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n","        1, 1, 1, 0, 1, 1, 0, 1])]\n","total_eval_loss\n","5.270726829767227\n","total_eval_accuracy\n","4.875\n","6\n","[tensor([[  101,  1996,  3482,  ...,     0,     0,     0],\n","        [  101, 13682,  2106,  ...,     0,     0,     0],\n","        [  101,  2984,  6369,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1037,  2338,  ...,     0,     0,     0],\n","        [  101,  1996,  9850,  ...,     0,     0,     0],\n","        [  101,  2057,  6476,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","        1, 0, 1, 0, 1, 0, 1, 0])]\n","total_eval_loss\n","6.293854981660843\n","total_eval_accuracy\n","5.71875\n","7\n","[tensor([[  101,  7673, 11308,  ...,     0,     0,     0],\n","        [  101,  1045,  2215,  ...,     0,     0,     0],\n","        [  101,  1045,  2175,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 15507,  1998,  ...,     0,     0,     0],\n","        [  101,  1996,  2879,  ...,     0,     0,     0],\n","        [  101,  5965,  3253,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","        1, 0, 0, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","6.705176264047623\n","total_eval_accuracy\n","6.625\n","8\n","[tensor([[  101,  1045,  2031,  ...,     0,     0,     0],\n","        [  101,  2027, 10847,  ...,     0,     0,     0],\n","        [  101,  2198,  2001,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  6947,  ...,     0,     0,     0],\n","        [  101,  2745,  4704,  ...,     0,     0,     0],\n","        [  101,  2065,  2198,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","6.979561060667038\n","total_eval_accuracy\n","7.53125\n","9\n","[tensor([[  101,  1996,  4268,  ...,     0,     0,     0],\n","        [  101,  1996, 14695,  ...,     0,     0,     0],\n","        [  101,  2002,  1005,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2984,  3373,  ...,     0,     0,     0],\n","        [  101,  2000,  5335,  ...,     0,     0,     0],\n","        [  101,  3419,  2743,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n","        1, 1, 1, 0, 1, 0, 1, 1])]\n","total_eval_loss\n","8.064705818891525\n","total_eval_accuracy\n","8.28125\n","10\n","[tensor([[  101,  1996,  3460,  ...,     0,     0,     0],\n","        [  101, 13382, 28201,  ...,     0,     0,     0],\n","        [  101,  1996,  1999,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  3869,  ...,     0,     0,     0],\n","        [  101,  2016,  2987,  ...,     0,     0,     0],\n","        [  101,  2471,  2296,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n","        1, 0, 0, 1, 0, 0, 0, 1])]\n","total_eval_loss\n","8.868690580129623\n","total_eval_accuracy\n","9.125\n","11\n","[tensor([[ 101, 2198, 5720,  ...,    0,    0,    0],\n","        [ 101, 2198, 5632,  ...,    0,    0,    0],\n","        [ 101, 2009, 2038,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 4463, 2001,  ...,    0,    0,    0],\n","        [ 101, 2984, 2003,  ...,    0,    0,    0],\n","        [ 101, 1996, 3482,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n","        0, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","9.543924897909164\n","total_eval_accuracy\n","10.0\n","12\n","[tensor([[ 101, 2027, 3236,  ...,    0,    0,    0],\n","        [ 101, 2016, 4025,  ...,    0,    0,    0],\n","        [ 101, 2087, 8626,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 1996, 2775,  ...,    0,    0,    0],\n","        [ 101, 2057, 2939,  ...,    0,    0,    0],\n","        [ 101, 2017, 2323,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 0, 1, 0, 1, 1, 1, 1])]\n","total_eval_loss\n","10.362362712621689\n","total_eval_accuracy\n","10.84375\n","13\n","[tensor([[  101,  1996,  2200,  ...,     0,     0,     0],\n","        [  101,  2014,  8114,  ...,     0,     0,     0],\n","        [  101,  2198,  6369,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2198,  6303,  ...,     0,     0,     0],\n","        [  101,  2040,  2079,  ...,     0,     0,     0],\n","        [  101,  2984, 11766,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","        0, 1, 1, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","10.677746087312698\n","total_eval_accuracy\n","11.78125\n","14\n","[tensor([[  101,  1045,  2741,  ...,     0,     0,     0],\n","        [  101,  2017,  2323,  ...,     0,     0,     0],\n","        [  101,  3021, 12984,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1999,  2394,  ...,     0,     0,     0],\n","        [  101,  1996,  6965,  ...,     0,     0,     0],\n","        [  101,  1045,  2387,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","11.11655017733574\n","total_eval_accuracy\n","12.625\n","15\n","[tensor([[  101,  1045,  2777,  ...,     0,     0,     0],\n","        [  101,  1996,  3608,  ...,     0,     0,     0],\n","        [  101,  2045, 29127,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2027,  2768,  ...,     0,     0,     0],\n","        [  101,  1045,  1005,  ...,     0,     0,     0],\n","        [  101,  1037,  2338,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n","        0, 0, 0, 1, 1, 1, 0, 1])]\n","total_eval_loss\n","11.906878143548965\n","total_eval_accuracy\n","13.46875\n","16\n","[tensor([[  101,  2017,  2064,  ...,     0,     0,     0],\n","        [  101,  1996,  2450,  ...,     0,     0,     0],\n","        [  101,  2023,  6045,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  2711,  ...,     0,     0,     0],\n","        [  101,  1996, 12779,  ...,     0,     0,     0],\n","        [  101,  1996,  2711,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n","        0, 0, 0, 1, 1, 0, 0, 1])]\n","total_eval_loss\n","12.771537154912949\n","total_eval_accuracy\n","14.28125\n","17\n","[tensor([[  101, 15507,  5292,  ...,     0,     0,     0],\n","        [  101,  3071,  3230,  ...,     0,     0,     0],\n","        [  101,  2006,  2029,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2829,  6055,  ...,     0,     0,     0],\n","        [  101,  2002,  8871,  ...,     0,     0,     0],\n","        [  101,  1996, 15034,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n","        1, 1, 0, 0, 0, 0, 0, 1])]\n","total_eval_loss\n","13.87933561205864\n","total_eval_accuracy\n","15.0625\n","18\n","[tensor([[  101,  2040,  2106,  ...,     0,     0,     0],\n","        [  101,  1996,  2417,  ...,     0,     0,     0],\n","        [  101, 19431,  2768,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2016,  2467,  ...,     0,     0,     0],\n","        [  101,  1045,  2097,  ...,     0,     0,     0],\n","        [  101,  2296,  3076,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","        0, 1, 1, 1, 1, 0, 1, 0])]\n","total_eval_loss\n","14.598445922136307\n","total_eval_accuracy\n","15.90625\n","19\n","[tensor([[  101,  2198,  2699,  ...,     0,     0,     0],\n","        [  101,  1996,  4049,  ...,     0,     0,     0],\n","        [  101, 11130,  2018,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2009,  2318,  ...,     0,     0,     0],\n","        [  101,  1996,  4944,  ...,     0,     0,     0],\n","        [  101,  5545,  3013,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n","        1, 0, 1, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","15.080131202936172\n","total_eval_accuracy\n","16.8125\n","20\n","[tensor([[  101,  3071,  8069,  ...,     0,     0,     0],\n","        [  101,  1045,  2066,  ...,     0,     0,     0],\n","        [  101,  8808, 12328,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  4572,  2741,  ...,     0,     0,     0],\n","        [  101,  1996,  3043,  ...,     0,     0,     0],\n","        [  101,  2045,  2145,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n","        1, 0, 1, 0, 0, 1, 1, 1])]\n","total_eval_loss\n","16.679427057504654\n","total_eval_accuracy\n","17.5\n","21\n","[tensor([[  101,  2198,  7164,  ...,     0,     0,     0],\n","        [  101,  2984,  2038,  ...,     0,     0,     0],\n","        [  101,  1045,  2387,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  3021,  2187,  ...,     0,     0,     0],\n","        [  101,  2031,  2017,  ...,     0,     0,     0],\n","        [  101,  1996, 14829,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n","        0, 0, 1, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","17.775981336832047\n","total_eval_accuracy\n","18.28125\n","22\n","[tensor([[ 101, 1037, 2158,  ...,    0,    0,    0],\n","        [ 101, 2027, 3191,  ...,    0,    0,    0],\n","        [ 101, 1045, 2031,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 8472, 8823,  ...,    0,    0,    0],\n","        [ 101, 1045, 1005,  ...,    0,    0,    0],\n","        [ 101, 1999, 2029,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n","        1, 0, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","18.188112676143646\n","total_eval_accuracy\n","19.21875\n","23\n","[tensor([[ 101, 2043, 2984,  ...,    0,    0,    0],\n","        [ 101, 2984, 6369,  ...,    0,    0,    0],\n","        [ 101, 5909, 2718,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 2009, 2001,  ...,    0,    0,    0],\n","        [ 101, 1996, 2332,  ...,    0,    0,    0],\n","        [ 101, 2040, 2106,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n","        1, 1, 1, 1, 0, 1, 1, 0])]\n","total_eval_loss\n","18.776611268520355\n","total_eval_accuracy\n","20.125\n","24\n","[tensor([[  101,  1045,  2052,  ...,     0,     0,     0],\n","        [  101,  6986,  4375,  ...,     0,     0,     0],\n","        [  101,  4116,  3631,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 15809, 14163,  ...,     0,     0,     0],\n","        [  101,  2057,  2031,  ...,     0,     0,     0],\n","        [  101,  4463,  3832,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n","        1, 1, 0, 1, 0, 0, 1, 0])]\n","total_eval_loss\n","19.313508927822113\n","total_eval_accuracy\n","21.03125\n","25\n","[tensor([[  101,  2002,  2939,  ...,     0,     0,     0],\n","        [  101,  2122, 17304,  ...,     0,     0,     0],\n","        [  101,  2079,  2025,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 12943, 14074,  ...,     0,     0,     0],\n","        [  101,  2054,  2016,  ...,     0,     0,     0],\n","        [  101,  2008,  3520,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n","        1, 1, 0, 1, 1, 1, 0, 0])]\n","total_eval_loss\n","20.1870499253273\n","total_eval_accuracy\n","21.84375\n","26\n","[tensor([[  101,  2984,  1005,  ...,     0,     0,     0],\n","        [  101,  1045,  2064,  ...,     0,     0,     0],\n","        [  101, 10508, 11248,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2070, 11746,  ...,     0,     0,     0],\n","        [  101, 10654, 15608,  ...,     0,     0,     0],\n","        [  101,  2984,  3248,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","20.639140188694\n","total_eval_accuracy\n","22.71875\n","27\n","Accuracy : 0.8414351851851852\n","Validation loss: 0.7644125995812593\n","Validation epoch 2 took 0:00:06 time\n","Epoch 3\n","  Batch    40  of    241.    Elapsed: 0:00:28.\n","  Batch    80  of    241.    Elapsed: 0:00:56.\n","  Batch   120  of    241.    Elapsed: 0:01:23.\n","  Batch   160  of    241.    Elapsed: 0:01:51.\n","  Batch   200  of    241.    Elapsed: 0:02:19.\n","  Batch   240  of    241.    Elapsed: 0:02:47.\n","Average training loss: 0.31126865066966636\n","Training epoch 3 took 0:02:47\n","Validation\n","0\n","[tensor([[  101,  1045,  2404,  ...,     0,     0,     0],\n","        [  101, 15595,  3281,  ...,     0,     0,     0],\n","        [  101, 11296,  1005,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  2346,  ...,     0,     0,     0],\n","        [  101,  1045,  5763,  ...,     0,     0,     0],\n","        [  101,  1996,  4424,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n","        0, 1, 0, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","0.2752458155155182\n","total_eval_accuracy\n","0.90625\n","1\n","[tensor([[  101,  8836, 20323,  ...,     0,     0,     0],\n","        [  101,  2984,  3555,  ...,     0,     0,     0],\n","        [  101, 17081,  2001,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1045,  4687,  ...,     0,     0,     0],\n","        [  101,  2990,  2089,  ...,     0,     0,     0],\n","        [  101,  2040,  2003,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n","        0, 1, 1, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","1.027497798204422\n","total_eval_accuracy\n","1.75\n","2\n","[tensor([[  101,  8594,  7844,  ...,     0,     0,     0],\n","        [  101,  1045,  4797,  ...,     0,     0,     0],\n","        [  101, 12306,  2741,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  7427,  ...,     0,     0,     0],\n","        [  101, 12684,  5225,  ...,     0,     0,     0],\n","        [  101,  2129,  9191,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","        0, 0, 1, 0, 1, 0, 1, 0])]\n","total_eval_loss\n","1.9460502564907074\n","total_eval_accuracy\n","2.53125\n","3\n","[tensor([[ 101, 3419, 2699,  ...,    0,    0,    0],\n","        [ 101, 2040, 2106,  ...,    0,    0,    0],\n","        [ 101, 1045, 4565,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 1045, 2435,  ...,    0,    0,    0],\n","        [ 101, 6529, 2179,  ...,    0,    0,    0],\n","        [ 101, 2054, 2016,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","        1, 1, 1, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","3.345067948102951\n","total_eval_accuracy\n","3.28125\n","4\n","[tensor([[  101,  1996,  3663,  ...,     0,     0,     0],\n","        [  101,  2009,  2003,  ...,     0,     0,     0],\n","        [  101,  1996,  2879,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1045,  2113,  ...,     0,     0,     0],\n","        [  101, 14736, 11741,  ...,     0,     0,     0],\n","        [  101,  2057,  2228,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n","        0, 1, 1, 0, 1, 1, 1, 0])]\n","total_eval_loss\n","4.42183718085289\n","total_eval_accuracy\n","4.09375\n","5\n","[tensor([[  101,  2027,  2056,  ...,     0,     0,     0],\n","        [  101,  2151,  2879,  ...,     0,     0,     0],\n","        [  101,  2027,  6884,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 11271,  2003,  ...,     0,     0,     0],\n","        [  101,  1045,  2031,  ...,     0,     0,     0],\n","        [  101,  2198,  2134,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n","        1, 1, 1, 0, 1, 1, 0, 1])]\n","total_eval_loss\n","5.270726829767227\n","total_eval_accuracy\n","4.875\n","6\n","[tensor([[  101,  1996,  3482,  ...,     0,     0,     0],\n","        [  101, 13682,  2106,  ...,     0,     0,     0],\n","        [  101,  2984,  6369,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1037,  2338,  ...,     0,     0,     0],\n","        [  101,  1996,  9850,  ...,     0,     0,     0],\n","        [  101,  2057,  6476,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","        1, 0, 1, 0, 1, 0, 1, 0])]\n","total_eval_loss\n","6.293854981660843\n","total_eval_accuracy\n","5.71875\n","7\n","[tensor([[  101,  7673, 11308,  ...,     0,     0,     0],\n","        [  101,  1045,  2215,  ...,     0,     0,     0],\n","        [  101,  1045,  2175,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 15507,  1998,  ...,     0,     0,     0],\n","        [  101,  1996,  2879,  ...,     0,     0,     0],\n","        [  101,  5965,  3253,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","        1, 0, 0, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","6.705176264047623\n","total_eval_accuracy\n","6.625\n","8\n","[tensor([[  101,  1045,  2031,  ...,     0,     0,     0],\n","        [  101,  2027, 10847,  ...,     0,     0,     0],\n","        [  101,  2198,  2001,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  6947,  ...,     0,     0,     0],\n","        [  101,  2745,  4704,  ...,     0,     0,     0],\n","        [  101,  2065,  2198,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","6.979561060667038\n","total_eval_accuracy\n","7.53125\n","9\n","[tensor([[  101,  1996,  4268,  ...,     0,     0,     0],\n","        [  101,  1996, 14695,  ...,     0,     0,     0],\n","        [  101,  2002,  1005,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2984,  3373,  ...,     0,     0,     0],\n","        [  101,  2000,  5335,  ...,     0,     0,     0],\n","        [  101,  3419,  2743,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n","        1, 1, 1, 0, 1, 0, 1, 1])]\n","total_eval_loss\n","8.064705818891525\n","total_eval_accuracy\n","8.28125\n","10\n","[tensor([[  101,  1996,  3460,  ...,     0,     0,     0],\n","        [  101, 13382, 28201,  ...,     0,     0,     0],\n","        [  101,  1996,  1999,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  3869,  ...,     0,     0,     0],\n","        [  101,  2016,  2987,  ...,     0,     0,     0],\n","        [  101,  2471,  2296,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n","        1, 0, 0, 1, 0, 0, 0, 1])]\n","total_eval_loss\n","8.868690580129623\n","total_eval_accuracy\n","9.125\n","11\n","[tensor([[ 101, 2198, 5720,  ...,    0,    0,    0],\n","        [ 101, 2198, 5632,  ...,    0,    0,    0],\n","        [ 101, 2009, 2038,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 4463, 2001,  ...,    0,    0,    0],\n","        [ 101, 2984, 2003,  ...,    0,    0,    0],\n","        [ 101, 1996, 3482,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n","        0, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","9.543924897909164\n","total_eval_accuracy\n","10.0\n","12\n","[tensor([[ 101, 2027, 3236,  ...,    0,    0,    0],\n","        [ 101, 2016, 4025,  ...,    0,    0,    0],\n","        [ 101, 2087, 8626,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 1996, 2775,  ...,    0,    0,    0],\n","        [ 101, 2057, 2939,  ...,    0,    0,    0],\n","        [ 101, 2017, 2323,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 0, 1, 0, 1, 1, 1, 1])]\n","total_eval_loss\n","10.362362712621689\n","total_eval_accuracy\n","10.84375\n","13\n","[tensor([[  101,  1996,  2200,  ...,     0,     0,     0],\n","        [  101,  2014,  8114,  ...,     0,     0,     0],\n","        [  101,  2198,  6369,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2198,  6303,  ...,     0,     0,     0],\n","        [  101,  2040,  2079,  ...,     0,     0,     0],\n","        [  101,  2984, 11766,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","        0, 1, 1, 1, 1, 1, 1, 0])]\n","total_eval_loss\n","10.677746087312698\n","total_eval_accuracy\n","11.78125\n","14\n","[tensor([[  101,  1045,  2741,  ...,     0,     0,     0],\n","        [  101,  2017,  2323,  ...,     0,     0,     0],\n","        [  101,  3021, 12984,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1999,  2394,  ...,     0,     0,     0],\n","        [  101,  1996,  6965,  ...,     0,     0,     0],\n","        [  101,  1045,  2387,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","11.11655017733574\n","total_eval_accuracy\n","12.625\n","15\n","[tensor([[  101,  1045,  2777,  ...,     0,     0,     0],\n","        [  101,  1996,  3608,  ...,     0,     0,     0],\n","        [  101,  2045, 29127,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2027,  2768,  ...,     0,     0,     0],\n","        [  101,  1045,  1005,  ...,     0,     0,     0],\n","        [  101,  1037,  2338,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n","        0, 0, 0, 1, 1, 1, 0, 1])]\n","total_eval_loss\n","11.906878143548965\n","total_eval_accuracy\n","13.46875\n","16\n","[tensor([[  101,  2017,  2064,  ...,     0,     0,     0],\n","        [  101,  1996,  2450,  ...,     0,     0,     0],\n","        [  101,  2023,  6045,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  1996,  2711,  ...,     0,     0,     0],\n","        [  101,  1996, 12779,  ...,     0,     0,     0],\n","        [  101,  1996,  2711,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n","        0, 0, 0, 1, 1, 0, 0, 1])]\n","total_eval_loss\n","12.771537154912949\n","total_eval_accuracy\n","14.28125\n","17\n","[tensor([[  101, 15507,  5292,  ...,     0,     0,     0],\n","        [  101,  3071,  3230,  ...,     0,     0,     0],\n","        [  101,  2006,  2029,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2829,  6055,  ...,     0,     0,     0],\n","        [  101,  2002,  8871,  ...,     0,     0,     0],\n","        [  101,  1996, 15034,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n","        1, 1, 0, 0, 0, 0, 0, 1])]\n","total_eval_loss\n","13.87933561205864\n","total_eval_accuracy\n","15.0625\n","18\n","[tensor([[  101,  2040,  2106,  ...,     0,     0,     0],\n","        [  101,  1996,  2417,  ...,     0,     0,     0],\n","        [  101, 19431,  2768,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2016,  2467,  ...,     0,     0,     0],\n","        [  101,  1045,  2097,  ...,     0,     0,     0],\n","        [  101,  2296,  3076,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","        0, 1, 1, 1, 1, 0, 1, 0])]\n","total_eval_loss\n","14.598445922136307\n","total_eval_accuracy\n","15.90625\n","19\n","[tensor([[  101,  2198,  2699,  ...,     0,     0,     0],\n","        [  101,  1996,  4049,  ...,     0,     0,     0],\n","        [  101, 11130,  2018,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2009,  2318,  ...,     0,     0,     0],\n","        [  101,  1996,  4944,  ...,     0,     0,     0],\n","        [  101,  5545,  3013,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n","        1, 0, 1, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","15.080131202936172\n","total_eval_accuracy\n","16.8125\n","20\n","[tensor([[  101,  3071,  8069,  ...,     0,     0,     0],\n","        [  101,  1045,  2066,  ...,     0,     0,     0],\n","        [  101,  8808, 12328,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  4572,  2741,  ...,     0,     0,     0],\n","        [  101,  1996,  3043,  ...,     0,     0,     0],\n","        [  101,  2045,  2145,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n","        1, 0, 1, 0, 0, 1, 1, 1])]\n","total_eval_loss\n","16.679427057504654\n","total_eval_accuracy\n","17.5\n","21\n","[tensor([[  101,  2198,  7164,  ...,     0,     0,     0],\n","        [  101,  2984,  2038,  ...,     0,     0,     0],\n","        [  101,  1045,  2387,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  3021,  2187,  ...,     0,     0,     0],\n","        [  101,  2031,  2017,  ...,     0,     0,     0],\n","        [  101,  1996, 14829,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n","        0, 0, 1, 1, 1, 0, 1, 1])]\n","total_eval_loss\n","17.775981336832047\n","total_eval_accuracy\n","18.28125\n","22\n","[tensor([[ 101, 1037, 2158,  ...,    0,    0,    0],\n","        [ 101, 2027, 3191,  ...,    0,    0,    0],\n","        [ 101, 1045, 2031,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 8472, 8823,  ...,    0,    0,    0],\n","        [ 101, 1045, 1005,  ...,    0,    0,    0],\n","        [ 101, 1999, 2029,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n","        1, 0, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","18.188112676143646\n","total_eval_accuracy\n","19.21875\n","23\n","[tensor([[ 101, 2043, 2984,  ...,    0,    0,    0],\n","        [ 101, 2984, 6369,  ...,    0,    0,    0],\n","        [ 101, 5909, 2718,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 2009, 2001,  ...,    0,    0,    0],\n","        [ 101, 1996, 2332,  ...,    0,    0,    0],\n","        [ 101, 2040, 2106,  ...,    0,    0,    0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n","        1, 1, 1, 1, 0, 1, 1, 0])]\n","total_eval_loss\n","18.776611268520355\n","total_eval_accuracy\n","20.125\n","24\n","[tensor([[  101,  1045,  2052,  ...,     0,     0,     0],\n","        [  101,  6986,  4375,  ...,     0,     0,     0],\n","        [  101,  4116,  3631,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 15809, 14163,  ...,     0,     0,     0],\n","        [  101,  2057,  2031,  ...,     0,     0,     0],\n","        [  101,  4463,  3832,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n","        1, 1, 0, 1, 0, 0, 1, 0])]\n","total_eval_loss\n","19.313508927822113\n","total_eval_accuracy\n","21.03125\n","25\n","[tensor([[  101,  2002,  2939,  ...,     0,     0,     0],\n","        [  101,  2122, 17304,  ...,     0,     0,     0],\n","        [  101,  2079,  2025,  ...,     0,     0,     0],\n","        ...,\n","        [  101, 12943, 14074,  ...,     0,     0,     0],\n","        [  101,  2054,  2016,  ...,     0,     0,     0],\n","        [  101,  2008,  3520,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n","        1, 1, 0, 1, 1, 1, 0, 0])]\n","total_eval_loss\n","20.1870499253273\n","total_eval_accuracy\n","21.84375\n","26\n","[tensor([[  101,  2984,  1005,  ...,     0,     0,     0],\n","        [  101,  1045,  2064,  ...,     0,     0,     0],\n","        [  101, 10508, 11248,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2070, 11746,  ...,     0,     0,     0],\n","        [  101, 10654, 15608,  ...,     0,     0,     0],\n","        [  101,  2984,  3248,  ...,     0,     0,     0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1])]\n","total_eval_loss\n","20.639140188694\n","total_eval_accuracy\n","22.71875\n","27\n","Accuracy : 0.8414351851851852\n","Validation loss: 0.7644125995812593\n","Validation epoch 3 took 0:00:07 time\n","Traning complete\n","Total training took 0:11:35 time\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OAoPvYNPYZK7","executionInfo":{"status":"ok","timestamp":1638821637957,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"ca748947-9032-4b15-e932-8c0abdb4fdd3"},"source":["training_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'Training loss': 0.06689792510491112,\n","  'Training time': '0:02:48',\n","  'Validation accuracy': 0.8414351851851852,\n","  'Validation loss': 0.7644125995812593,\n","  'Validation time': '0:00:07',\n","  'epoch': 1},\n"," {'Training loss': 0.29765367364564993,\n","  'Training time': '0:02:47',\n","  'Validation accuracy': 0.8414351851851852,\n","  'Validation loss': 0.7644125995812593,\n","  'Validation time': '0:00:07',\n","  'epoch': 2},\n"," {'Training loss': 0.2932015156307687,\n","  'Training time': '0:02:47',\n","  'Validation accuracy': 0.8414351851851852,\n","  'Validation loss': 0.7644125995812593,\n","  'Validation time': '0:00:06',\n","  'epoch': 3},\n"," {'Training loss': 0.31126865066966636,\n","  'Training time': '0:02:47',\n","  'Validation accuracy': 0.8414351851851852,\n","  'Validation loss': 0.7644125995812593,\n","  'Validation time': '0:00:07',\n","  'epoch': 4}]"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"mF-PwhGF_4f9","executionInfo":{"status":"ok","timestamp":1638822447991,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"befdaf71-1257-4a74-fad7-8bf78f66ec44"},"source":["import pandas as pd\n","\n","pd.set_option('precision', 2)\n","\n","df_stats = pd.DataFrame(data = training_stats)\n","df_stats = df_stats.set_index('epoch')\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training loss</th>\n","      <th>Validation loss</th>\n","      <th>Validation accuracy</th>\n","      <th>Training time</th>\n","      <th>Validation time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.07</td>\n","      <td>0.76</td>\n","      <td>0.84</td>\n","      <td>0:02:48</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.30</td>\n","      <td>0.76</td>\n","      <td>0.84</td>\n","      <td>0:02:47</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.29</td>\n","      <td>0.76</td>\n","      <td>0.84</td>\n","      <td>0:02:47</td>\n","      <td>0:00:06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.31</td>\n","      <td>0.76</td>\n","      <td>0.84</td>\n","      <td>0:02:47</td>\n","      <td>0:00:07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training loss  Validation loss  ...  Training time Validation time\n","epoch                                  ...                               \n","1               0.07             0.76  ...        0:02:48         0:00:07\n","2               0.30             0.76  ...        0:02:47         0:00:07\n","3               0.29             0.76  ...        0:02:47         0:00:06\n","4               0.31             0.76  ...        0:02:47         0:00:07\n","\n","[4 rows x 5 columns]"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"VlN51FgURgZA"},"source":["# Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on.\n","# If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"R7aQUoymnXbd","executionInfo":{"status":"ok","timestamp":1638822453648,"user_tz":-330,"elapsed":771,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"69d58735-965b-4fd3-9098-12ef2c18ea6c"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Validation loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"y40XN4aPoBjc","executionInfo":{"status":"ok","timestamp":1638822517883,"user_tz":-330,"elapsed":814,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"088aeb0e-e0a9-4310-cd5d-29a69de9ec94"},"source":["# Apply same steps to test dataset\n","\n","import pandas as pd\n","\n","df_test = pd.read_csv('./cola_public/raw/in_domain_dev.tsv', delimiter = '\\t', header = None, names = ['Sentence_source', 'Label', 'Label_notes', 'Sentence'])\n","print(df.shape)\n","df_test"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(8551, 4)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence_source</th>\n","      <th>Label</th>\n","      <th>Label_notes</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>The sailors rode the breeze clear of the rocks.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>The weights made the rope stretch over the pul...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>The mechanical doll wriggled itself loose.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cj99</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>If you had eaten more, you would want less.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cj99</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>As you eat the most, you want the least.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>522</th>\n","      <td>ad03</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>I would like to could swim</td>\n","    </tr>\n","    <tr>\n","      <th>523</th>\n","      <td>ad03</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>I kicked myself</td>\n","    </tr>\n","    <tr>\n","      <th>524</th>\n","      <td>ad03</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>The bookcase ran</td>\n","    </tr>\n","    <tr>\n","      <th>525</th>\n","      <td>ad03</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>I shaved myself.</td>\n","    </tr>\n","    <tr>\n","      <th>526</th>\n","      <td>ad03</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>Anson became a muscle bound.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>527 rows × 4 columns</p>\n","</div>"],"text/plain":["    Sentence_source  ...                                           Sentence\n","0              gj04  ...    The sailors rode the breeze clear of the rocks.\n","1              gj04  ...  The weights made the rope stretch over the pul...\n","2              gj04  ...         The mechanical doll wriggled itself loose.\n","3              cj99  ...        If you had eaten more, you would want less.\n","4              cj99  ...           As you eat the most, you want the least.\n","..              ...  ...                                                ...\n","522            ad03  ...                         I would like to could swim\n","523            ad03  ...                                    I kicked myself\n","524            ad03  ...                                   The bookcase ran\n","525            ad03  ...                                   I shaved myself.\n","526            ad03  ...                       Anson became a muscle bound.\n","\n","[527 rows x 4 columns]"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"93r64PW0pUTU"},"source":["# Get the lists of sentences and their labels.\n","\n","test_sentences = df_test.Sentence.values\n","test_labels = df_test.Label.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pP1jUzVpySN","executionInfo":{"status":"ok","timestamp":1638822524513,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"2b8ba10b-93ca-4a83-f0f0-07363d8424f5"},"source":["max_len = 0\n","\n","for sent in test_sentences:\n","  input_ids = tokenizer.encode(sent, add_special_tokens = True)\n","  max_len = max(max_len, len(input_ids))\n","  \n","print('Maximum sentence length: ', max_len)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sentence length:  31\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HxkgP5-Oq7oa","executionInfo":{"status":"ok","timestamp":1638822562627,"user_tz":-330,"elapsed":526,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"936109f5-5587-4a7f-f828-97facc4b9c9a"},"source":["# Encoding just one sentence\n","\n","encoded_dict = tokenizer.encode_plus(test_sentences[0], add_special_tokens=True, max_length=64, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n","print(encoded_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[  101,  1996, 11279,  8469,  1996,  9478,  3154,  1997,  1996,  5749,\n","          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRSDX0qhqeLp","executionInfo":{"status":"ok","timestamp":1638824164608,"user_tz":-330,"elapsed":574,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"7eed4b1c-496b-4e97-a4ef-ddb758a8de86"},"source":["# Tokenize all of the test sentences and map the tokens to thier word IDs.\n","\n","test_input_ids = []\n","test_attention_masks = []\n","\n","for sent in test_sentences:\n","  test_encoded_dict = tokenizer.encode_plus(sent, add_special_tokens=True, max_length=64, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n","  test_input_ids.append(test_encoded_dict['input_ids'])\n","  test_attention_masks.append(test_encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors\n","\n","test_input_ids = torch.cat(test_input_ids, dim=0)\n","test_attention_masks = torch.cat(test_attention_masks, dim=0)\n","test_labels = torch.tensor(test_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  from ipykernel import kernelapp as app\n"]}]},{"cell_type":"code","metadata":{"id":"Bb7miaqAtFWc"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n","\n","batch_size = 32\n","\n","test_dataloader = DataLoader(test_dataset, batch_size = batch_size, sampler = SequentialSampler(test_dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0GsJ6Xvttl8","executionInfo":{"status":"ok","timestamp":1638824181639,"user_tz":-330,"elapsed":3897,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"8b294dad-288f-4cdd-8ad8-fc5504603041"},"source":["import random\n","import numpy as np\n","import time\n","\n","t0 = time.time()\n","\n","print('Testing')\n","\n","model.eval()   # Put the model in evaluation mode--the dropout layers behave differently during evaluation\n","\n","total_test_accuracy = 0\n","total_test_loss = 0\n","predictions = []\n","true_labels = []\n","\n","for batch in test_dataloader:\n","\n","  b_input_ids = batch[0].to(device)\n","  b_attention_masks = batch[1].to(device)\n","  b_labels = batch[2].to(device)\n","\n","  # Tell pytorch not to bother with constructing the compute graph during the forward pass, since this is only needed for backprop (training)\n","  with torch.no_grad():\n","    result = model(b_input_ids, token_type_ids=None, attention_mask=b_attention_masks, return_dict = True)\n","  print(result)\n","  # loss = result.loss\n","  logits = result.logits\n","\n","  # total_test_loss += loss.item()\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  print(logits)\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","  # calculate the accuracy for this batch of test sentences and accumulate it over all batches\n","  total_test_accuracy += flat_accuracy(logits, label_ids)\n","\n","avg_test_accuracy = total_test_accuracy / len(test_dataloader)   # We will calculate accuracy(MCC) of entire test set by using pred and true labels\n","print(len(test_dataloader))\n","print('Accuracy : {}'.format(avg_test_accuracy))  \n","\n","avg_test_loss = total_test_loss/ len(test_dataloader)\n","test_time = format_time(time.time() - t0)\n","print('Test loss: {}'.format(avg_test_loss))\n","print('Test testing took {} time'.format(test_time))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.5254,  3.9959],\n","        [-2.5591,  3.2532],\n","        [-2.5295,  2.9818],\n","        [-3.4476,  3.9563],\n","        [-1.7989,  1.9683],\n","        [-1.4432,  1.8111],\n","        [-3.0873,  3.4700],\n","        [-2.9456,  3.6314],\n","        [-1.5224,  2.1811],\n","        [-3.0674,  3.5421],\n","        [-3.4465,  3.9475],\n","        [-3.4696,  4.0761],\n","        [-2.8409,  3.6208],\n","        [-1.7005,  2.2610],\n","        [-2.4646,  3.1499],\n","        [-2.6232,  3.2227],\n","        [ 2.0452, -2.8220],\n","        [-2.9624,  3.3769],\n","        [-3.4870,  4.1230],\n","        [-3.4746,  4.0708],\n","        [-3.4707,  4.1036],\n","        [-3.4387,  4.1071],\n","        [-3.5604,  4.0178],\n","        [-1.3945,  1.9555],\n","        [-3.5852,  4.0171],\n","        [-3.3817,  4.0721],\n","        [-3.5113,  4.2048],\n","        [-3.4309,  3.9742],\n","        [-0.0109, -0.3807],\n","        [-1.8621,  1.4483],\n","        [-3.4397,  4.0520],\n","        [-2.6904,  3.2755]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-3.5254416   3.9959025 ]\n"," [-2.5590782   3.2531974 ]\n"," [-2.5294914   2.9818192 ]\n"," [-3.447632    3.9563315 ]\n"," [-1.7988747   1.9683353 ]\n"," [-1.4431792   1.8111213 ]\n"," [-3.0872672   3.4700236 ]\n"," [-2.9456496   3.631402  ]\n"," [-1.5224298   2.1810975 ]\n"," [-3.0673504   3.542145  ]\n"," [-3.4465084   3.9474978 ]\n"," [-3.469598    4.0761213 ]\n"," [-2.840871    3.620776  ]\n"," [-1.7005321   2.2610378 ]\n"," [-2.4645858   3.1499085 ]\n"," [-2.623196    3.2227316 ]\n"," [ 2.045242   -2.8219688 ]\n"," [-2.9623904   3.3768556 ]\n"," [-3.487017    4.1230307 ]\n"," [-3.4746006   4.070845  ]\n"," [-3.4706836   4.103614  ]\n"," [-3.4387062   4.1071377 ]\n"," [-3.5603967   4.017776  ]\n"," [-1.394515    1.9555305 ]\n"," [-3.5851655   4.0171347 ]\n"," [-3.381671    4.072087  ]\n"," [-3.5113225   4.2048354 ]\n"," [-3.4308515   3.9742498 ]\n"," [-0.01094292 -0.38067114]\n"," [-1.8621471   1.4482973 ]\n"," [-3.4397278   4.052019  ]\n"," [-2.6904006   3.2754598 ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.2680,  3.9058],\n","        [-3.2471,  3.8923],\n","        [ 2.1428, -2.9217],\n","        [-3.5653,  4.1233],\n","        [-3.4414,  4.1886],\n","        [-2.0217,  2.5646],\n","        [-3.3240,  3.7562],\n","        [ 1.0535, -1.8164],\n","        [-3.2796,  3.5730],\n","        [-3.1652,  3.6476],\n","        [-3.2701,  3.9647],\n","        [-3.3341,  4.0901],\n","        [ 2.6097, -3.4974],\n","        [ 2.6462, -3.4126],\n","        [-3.0628,  3.6477],\n","        [ 1.2573, -2.2881],\n","        [-3.3288,  3.9716],\n","        [-3.5009,  3.9988],\n","        [-3.5623,  4.2053],\n","        [ 0.1309, -0.3307],\n","        [-3.4426,  4.0302],\n","        [-3.4502,  3.8777],\n","        [ 2.0387, -2.8956],\n","        [-2.9638,  3.4687],\n","        [-2.7361,  3.2565],\n","        [ 0.2341, -0.5274],\n","        [ 0.5544, -0.6774],\n","        [-1.7788,  2.2098],\n","        [ 2.3852, -3.2441],\n","        [-2.6225,  3.0453],\n","        [-3.4327,  3.7587],\n","        [-3.3315,  3.7386]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-3.2679522   3.9057662 ]\n"," [-3.2470741   3.8922882 ]\n"," [ 2.1428168  -2.9217107 ]\n"," [-3.5653145   4.123287  ]\n"," [-3.4413595   4.1885724 ]\n"," [-2.0216944   2.5646021 ]\n"," [-3.3239956   3.7561774 ]\n"," [ 1.0534589  -1.81636   ]\n"," [-3.2795963   3.5730064 ]\n"," [-3.1652079   3.6476057 ]\n"," [-3.2700846   3.9647014 ]\n"," [-3.3341105   4.0901318 ]\n"," [ 2.6096673  -3.4973578 ]\n"," [ 2.646172   -3.4126291 ]\n"," [-3.062823    3.647658  ]\n"," [ 1.2572877  -2.2880764 ]\n"," [-3.3288193   3.9715805 ]\n"," [-3.5009253   3.9988422 ]\n"," [-3.5622833   4.205286  ]\n"," [ 0.13087454 -0.33071047]\n"," [-3.4425778   4.0302477 ]\n"," [-3.450209    3.8777013 ]\n"," [ 2.0386682  -2.8955815 ]\n"," [-2.9638467   3.4686873 ]\n"," [-2.736067    3.2565358 ]\n"," [ 0.23409612 -0.5273528 ]\n"," [ 0.5544095  -0.677394  ]\n"," [-1.778814    2.2097788 ]\n"," [ 2.3852472  -3.244111  ]\n"," [-2.622468    3.0452616 ]\n"," [-3.432679    3.7587168 ]\n"," [-3.3315349   3.7386494 ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.1192,  3.8351],\n","        [ 3.0031, -3.8362],\n","        [-3.5453,  4.1691],\n","        [-2.1641,  2.5482],\n","        [-2.5441,  2.6798],\n","        [-2.4092,  3.0147],\n","        [-2.1139,  2.6570],\n","        [-3.3553,  4.0539],\n","        [-2.9270,  3.4171],\n","        [ 2.7612, -3.5976],\n","        [-2.4912,  2.9187],\n","        [-1.6769,  2.2582],\n","        [-3.5366,  3.9463],\n","        [ 2.7662, -3.6176],\n","        [-3.4900,  3.9794],\n","        [-3.2196,  3.4562],\n","        [ 2.8442, -3.7342],\n","        [-2.3562,  3.0217],\n","        [-3.1563,  3.7528],\n","        [-3.1759,  3.5720],\n","        [-2.2913,  2.9950],\n","        [-3.3226,  3.7204],\n","        [ 2.8765, -3.6532],\n","        [-3.4855,  4.0263],\n","        [-2.6484,  3.2100],\n","        [-2.1128,  2.5301],\n","        [-2.6156,  2.6454],\n","        [ 2.8830, -3.6915],\n","        [-3.5823,  4.2311],\n","        [-3.4510,  4.0245],\n","        [-2.5695,  2.7734],\n","        [ 2.4396, -3.2323]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-3.1191971  3.8350513]\n"," [ 3.0030973 -3.8361661]\n"," [-3.5453455  4.1691065]\n"," [-2.1640894  2.5481513]\n"," [-2.544055   2.67979  ]\n"," [-2.409231   3.0146685]\n"," [-2.1139162  2.6569586]\n"," [-3.355262   4.053871 ]\n"," [-2.9270396  3.4170759]\n"," [ 2.7611659 -3.5975847]\n"," [-2.49122    2.9186697]\n"," [-1.6768911  2.258173 ]\n"," [-3.5365894  3.9462748]\n"," [ 2.7661521 -3.617622 ]\n"," [-3.4899597  3.9793766]\n"," [-3.2195919  3.4562356]\n"," [ 2.844204  -3.7342257]\n"," [-2.3561957  3.021726 ]\n"," [-3.1563075  3.752789 ]\n"," [-3.1759305  3.5720222]\n"," [-2.2912755  2.9949646]\n"," [-3.322648   3.720435 ]\n"," [ 2.876457  -3.6532464]\n"," [-3.485518   4.0262504]\n"," [-2.6484427  3.2100265]\n"," [-2.1128469  2.5301056]\n"," [-2.615554   2.6453621]\n"," [ 2.8830276 -3.6915123]\n"," [-3.5823374  4.2310696]\n"," [-3.450971   4.024495 ]\n"," [-2.5694854  2.7733524]\n"," [ 2.4396198 -3.2323422]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-2.8280,  3.2840],\n","        [-3.1662,  3.6294],\n","        [-3.2400,  3.7685],\n","        [-3.2746,  3.5443],\n","        [-3.4549,  3.8893],\n","        [-3.2366,  3.5330],\n","        [-3.0990,  3.5528],\n","        [-1.8625,  2.2500],\n","        [-3.4278,  3.8674],\n","        [-2.2668,  2.7995],\n","        [-3.5008,  4.0299],\n","        [-3.5971,  4.0791],\n","        [-0.7156,  1.0144],\n","        [ 1.0831, -1.5307],\n","        [-3.1817,  3.3857],\n","        [ 3.0613, -3.7486],\n","        [-3.3374,  3.9199],\n","        [-3.0126,  3.4648],\n","        [ 3.0078, -3.7807],\n","        [-3.3086,  3.8513],\n","        [-2.3481,  2.4032],\n","        [ 2.8937, -3.6653],\n","        [-3.3094,  3.8380],\n","        [-2.9663,  3.2284],\n","        [-3.0668,  3.5852],\n","        [-3.4080,  4.0290],\n","        [-0.1052,  0.0156],\n","        [-2.5969,  2.6963],\n","        [-3.4467,  3.9228],\n","        [-3.0901,  3.7008],\n","        [-3.6052,  3.9965],\n","        [-2.4078,  2.6716]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-2.827958    3.2839978 ]\n"," [-3.1661525   3.6294017 ]\n"," [-3.2400231   3.7685132 ]\n"," [-3.2745593   3.5442855 ]\n"," [-3.4549239   3.8893404 ]\n"," [-3.2366076   3.5329547 ]\n"," [-3.0990388   3.552791  ]\n"," [-1.862492    2.2500167 ]\n"," [-3.427796    3.8674326 ]\n"," [-2.2667654   2.7995234 ]\n"," [-3.5008063   4.0299153 ]\n"," [-3.5970712   4.0790806 ]\n"," [-0.71564466  1.0144153 ]\n"," [ 1.0831416  -1.5306871 ]\n"," [-3.1816804   3.3857186 ]\n"," [ 3.061322   -3.7486348 ]\n"," [-3.3373954   3.9198694 ]\n"," [-3.0125568   3.464794  ]\n"," [ 3.0077698  -3.7806816 ]\n"," [-3.3085728   3.8513036 ]\n"," [-2.3481262   2.4031653 ]\n"," [ 2.893706   -3.6652584 ]\n"," [-3.3094392   3.8379908 ]\n"," [-2.966332    3.2283564 ]\n"," [-3.0667694   3.5852025 ]\n"," [-3.4080071   4.0289536 ]\n"," [-0.10515763  0.01563175]\n"," [-2.596933    2.6963272 ]\n"," [-3.446708    3.9227934 ]\n"," [-3.0901244   3.7007997 ]\n"," [-3.6052172   3.9965298 ]\n"," [-2.4077988   2.6715868 ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[ 3.0312, -3.7601],\n","        [ 3.1032, -3.8297],\n","        [-3.5091,  4.0184],\n","        [-3.4134,  4.0198],\n","        [ 0.9781, -1.8288],\n","        [-3.4277,  3.9518],\n","        [-2.6779,  3.3112],\n","        [ 2.4733, -3.3017],\n","        [-3.1343,  3.8314],\n","        [ 1.7047, -2.4209],\n","        [-2.8886,  3.3529],\n","        [-3.1267,  3.4442],\n","        [ 1.2597, -2.0065],\n","        [-3.2259,  3.9109],\n","        [-2.4596,  3.2430],\n","        [-3.3523,  3.9934],\n","        [-2.6038,  3.3523],\n","        [-2.6509,  3.2841],\n","        [ 2.8237, -3.7476],\n","        [-3.0731,  3.8088],\n","        [-2.7041,  3.4368],\n","        [-3.5343,  4.1655],\n","        [-3.5395,  4.0920],\n","        [ 2.6106, -3.3699],\n","        [-2.6964,  3.3604],\n","        [-1.4087,  1.7107],\n","        [-3.1764,  3.7877],\n","        [-2.2615,  2.5029],\n","        [-3.6582,  4.1602],\n","        [-3.1701,  3.5955],\n","        [-3.0890,  3.5092],\n","        [-3.0780,  3.5904]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[ 3.0312195 -3.7601447]\n"," [ 3.1032252 -3.8297062]\n"," [-3.509071   4.018427 ]\n"," [-3.413356   4.0197973]\n"," [ 0.9781067 -1.828813 ]\n"," [-3.4276996  3.951786 ]\n"," [-2.6778712  3.311156 ]\n"," [ 2.4733274 -3.301679 ]\n"," [-3.134295   3.8314073]\n"," [ 1.7046918 -2.4208672]\n"," [-2.8886116  3.352876 ]\n"," [-3.1267426  3.4442008]\n"," [ 1.2596968 -2.006472 ]\n"," [-3.22592    3.91089  ]\n"," [-2.459618   3.2430067]\n"," [-3.3523285  3.9933708]\n"," [-2.603766   3.352263 ]\n"," [-2.6508908  3.2840865]\n"," [ 2.823724  -3.7476096]\n"," [-3.073083   3.8088088]\n"," [-2.704117   3.4368393]\n"," [-3.534324   4.165478 ]\n"," [-3.5395222  4.0920115]\n"," [ 2.6106021 -3.3699155]\n"," [-2.696429   3.3603876]\n"," [-1.40874    1.7107134]\n"," [-3.1763906  3.7877293]\n"," [-2.2615461  2.502938 ]\n"," [-3.6582499  4.1602287]\n"," [-3.170098   3.595505 ]\n"," [-3.0890374  3.5091908]\n"," [-3.0779583  3.5904496]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-1.1008,  1.0987],\n","        [-3.1712,  3.6321],\n","        [-3.5706,  4.1008],\n","        [-3.6392,  4.1098],\n","        [ 2.6883, -3.3823],\n","        [ 3.0336, -3.7419],\n","        [-3.4096,  4.0570],\n","        [-2.7698,  3.4111],\n","        [-3.3711,  4.0527],\n","        [-2.9498,  3.1594],\n","        [ 3.0104, -3.7279],\n","        [-2.3863,  2.9785],\n","        [-2.3063,  1.6767],\n","        [-2.2551,  2.8238],\n","        [-3.1674,  3.5943],\n","        [ 1.6807, -2.4274],\n","        [-1.7377,  2.4173],\n","        [-3.4159,  4.0457],\n","        [-3.3560,  3.7231],\n","        [ 1.7955, -2.2852],\n","        [-3.6019,  4.1972],\n","        [-3.4552,  3.8799],\n","        [-3.4311,  4.0946],\n","        [-3.0549,  3.5244],\n","        [-3.2374,  3.8842],\n","        [-3.2784,  3.9018],\n","        [-3.7056,  4.0976],\n","        [-3.1804,  3.6200],\n","        [-1.6923,  1.7997],\n","        [-2.2749,  2.7722],\n","        [-2.3192,  2.6664],\n","        [ 2.4718, -3.2762]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-1.100778   1.0986735]\n"," [-3.1712153  3.632082 ]\n"," [-3.570625   4.100768 ]\n"," [-3.639223   4.1098304]\n"," [ 2.6882536 -3.3822505]\n"," [ 3.0335767 -3.7419295]\n"," [-3.4095783  4.0569715]\n"," [-2.7698355  3.4110634]\n"," [-3.3711452  4.0526514]\n"," [-2.9497986  3.1594148]\n"," [ 3.010383  -3.7279255]\n"," [-2.3863368  2.9784844]\n"," [-2.3063016  1.6767371]\n"," [-2.2550974  2.8237576]\n"," [-3.167409   3.5942807]\n"," [ 1.6807492 -2.4273515]\n"," [-1.7377026  2.4173014]\n"," [-3.415949   4.0456686]\n"," [-3.3559537  3.7231352]\n"," [ 1.7954749 -2.2851744]\n"," [-3.601916   4.1971564]\n"," [-3.4552171  3.8798635]\n"," [-3.4310794  4.094565 ]\n"," [-3.054932   3.5243807]\n"," [-3.237398   3.884159 ]\n"," [-3.2784028  3.9017925]\n"," [-3.7055717  4.0976133]\n"," [-3.1803505  3.6200218]\n"," [-1.6922556  1.7997215]\n"," [-2.2749133  2.7722397]\n"," [-2.3191729  2.6663973]\n"," [ 2.471779  -3.276179 ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[ 2.9137, -3.6916],\n","        [-3.4780,  4.0129],\n","        [-0.8707,  0.9981],\n","        [-3.5666,  4.2261],\n","        [ 2.1498, -3.0058],\n","        [-2.7143,  3.4464],\n","        [-3.0887,  3.7434],\n","        [-2.4510,  3.1138],\n","        [-2.9492,  2.9122],\n","        [ 2.6755, -3.5369],\n","        [-3.0565,  3.3915],\n","        [-3.4905,  4.1197],\n","        [-3.5491,  4.2299],\n","        [-3.4021,  4.0853],\n","        [ 2.6210, -3.4660],\n","        [-3.5410,  4.0091],\n","        [-3.5435,  4.1672],\n","        [ 2.1718, -3.0694],\n","        [-3.4641,  4.0634],\n","        [-3.1038,  3.6350],\n","        [-0.7590,  0.7792],\n","        [-2.8227,  3.5005],\n","        [-3.5417,  4.1136],\n","        [-3.4959,  4.1116],\n","        [-3.0723,  3.7488],\n","        [ 2.6505, -3.5075],\n","        [ 0.6446, -1.5828],\n","        [-3.4663,  3.8670],\n","        [ 2.5694, -3.3666],\n","        [-3.4845,  4.1746],\n","        [-3.1385,  3.7505],\n","        [-3.3380,  3.7212]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[ 2.9137275  -3.6915736 ]\n"," [-3.4780023   4.0129466 ]\n"," [-0.87070006  0.99813694]\n"," [-3.5666165   4.22613   ]\n"," [ 2.149832   -3.005801  ]\n"," [-2.7142897   3.4464188 ]\n"," [-3.0887184   3.7434072 ]\n"," [-2.4510498   3.1138432 ]\n"," [-2.949223    2.9121904 ]\n"," [ 2.675456   -3.536912  ]\n"," [-3.0564663   3.3915062 ]\n"," [-3.490482    4.1196675 ]\n"," [-3.5491047   4.229941  ]\n"," [-3.4021428   4.0852804 ]\n"," [ 2.6210456  -3.4660237 ]\n"," [-3.5409882   4.009092  ]\n"," [-3.54346     4.167176  ]\n"," [ 2.1718059  -3.069389  ]\n"," [-3.464093    4.0634284 ]\n"," [-3.103822    3.6350281 ]\n"," [-0.75897074  0.77920175]\n"," [-2.8227234   3.5005007 ]\n"," [-3.5417302   4.113556  ]\n"," [-3.4959326   4.111617  ]\n"," [-3.0723443   3.748754  ]\n"," [ 2.650528   -3.5075219 ]\n"," [ 0.6445917  -1.5828246 ]\n"," [-3.4663138   3.8670235 ]\n"," [ 2.5694273  -3.3665652 ]\n"," [-3.4844856   4.174617  ]\n"," [-3.1384923   3.7504761 ]\n"," [-3.338001    3.721247  ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[ 2.3458, -3.1498],\n","        [ 1.5717, -2.2642],\n","        [ 3.0187, -3.7919],\n","        [-0.7227, -0.0933],\n","        [-3.4707,  4.2024],\n","        [ 2.0993, -2.9001],\n","        [ 2.6201, -3.4522],\n","        [-2.8771,  3.4555],\n","        [ 2.5853, -3.2860],\n","        [-3.5424,  4.0959],\n","        [-3.4501,  4.1325],\n","        [-3.3257,  3.9510],\n","        [ 2.7059, -3.6058],\n","        [-2.6839,  3.2149],\n","        [-3.4743,  4.2386],\n","        [-3.4641,  4.1797],\n","        [-3.3990,  3.8843],\n","        [-3.4238,  4.1971],\n","        [-3.5916,  4.0954],\n","        [-3.4149,  3.8460],\n","        [-3.5214,  4.0753],\n","        [-3.3995,  4.0698],\n","        [ 3.0815, -3.8263],\n","        [-3.3592,  3.8756],\n","        [-2.5137,  2.7419],\n","        [-3.5079,  4.1515],\n","        [-3.2242,  4.0096],\n","        [-3.5120,  4.1342],\n","        [ 3.0636, -3.8186],\n","        [-3.5351,  4.2010],\n","        [-3.1037,  3.8205],\n","        [-0.4436, -0.2601]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[ 2.3458178  -3.1498332 ]\n"," [ 1.5716962  -2.2641785 ]\n"," [ 3.0186968  -3.7918699 ]\n"," [-0.72266245 -0.09326719]\n"," [-3.4706807   4.202385  ]\n"," [ 2.0993373  -2.9001427 ]\n"," [ 2.6200845  -3.4522374 ]\n"," [-2.8770928   3.4554698 ]\n"," [ 2.5853016  -3.2859561 ]\n"," [-3.5424356   4.09586   ]\n"," [-3.450097    4.132489  ]\n"," [-3.3256786   3.9510086 ]\n"," [ 2.705914   -3.6058185 ]\n"," [-2.6838746   3.2148705 ]\n"," [-3.4743445   4.2386036 ]\n"," [-3.4640827   4.1797366 ]\n"," [-3.398985    3.8842597 ]\n"," [-3.4237869   4.1970773 ]\n"," [-3.5916305   4.0954466 ]\n"," [-3.41492     3.8460016 ]\n"," [-3.5214393   4.075282  ]\n"," [-3.3995159   4.0698223 ]\n"," [ 3.0815482  -3.8263097 ]\n"," [-3.3592443   3.875649  ]\n"," [-2.5136597   2.7418656 ]\n"," [-3.5079443   4.151494  ]\n"," [-3.2242312   4.009555  ]\n"," [-3.5120058   4.134155  ]\n"," [ 3.063593   -3.8186433 ]\n"," [-3.5350614   4.201047  ]\n"," [-3.1037054   3.820452  ]\n"," [-0.44355527 -0.26010364]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.2797,  3.9586],\n","        [ 2.9362, -3.7112],\n","        [-2.7194,  3.4258],\n","        [-2.1647,  1.7661],\n","        [-2.9064,  3.5031],\n","        [-1.0106,  1.0607],\n","        [-2.0703,  2.4999],\n","        [-3.0998,  3.7585],\n","        [-3.2603,  3.6410],\n","        [-3.0327,  3.3641],\n","        [ 1.5428, -2.4508],\n","        [-2.2887,  2.8181],\n","        [-1.8925,  2.4863],\n","        [-1.9816,  2.3626],\n","        [ 2.6889, -3.5769],\n","        [ 2.9457, -3.7712],\n","        [-3.4451,  4.1017],\n","        [-0.9427,  1.0911],\n","        [-2.3048,  2.0099],\n","        [-3.5222,  4.1602],\n","        [-3.4976,  3.7907],\n","        [-2.3124,  2.7736],\n","        [ 2.7103, -3.5757],\n","        [-3.4095,  4.0902],\n","        [ 2.6913, -3.5022],\n","        [ 2.6897, -3.6117],\n","        [-3.5783,  4.1871],\n","        [-3.1177,  3.3090],\n","        [-3.1523,  3.7393],\n","        [-3.3056,  3.9664],\n","        [-2.2861,  3.0202],\n","        [-2.3932,  3.0152]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-3.2797408  3.9585648]\n"," [ 2.9361508 -3.711158 ]\n"," [-2.7194462  3.4257705]\n"," [-2.1646953  1.7660943]\n"," [-2.9064057  3.5031376]\n"," [-1.0105717  1.0606794]\n"," [-2.0703292  2.4998653]\n"," [-3.0998363  3.7585487]\n"," [-3.2602751  3.641026 ]\n"," [-3.0327013  3.3640625]\n"," [ 1.5427887 -2.4507842]\n"," [-2.2887394  2.8181064]\n"," [-1.8925472  2.486298 ]\n"," [-1.981588   2.3626301]\n"," [ 2.6889462 -3.576901 ]\n"," [ 2.9456675 -3.7711802]\n"," [-3.445068   4.1017256]\n"," [-0.9427085  1.0910696]\n"," [-2.304809   2.0099456]\n"," [-3.5221958  4.16019  ]\n"," [-3.497621   3.79068  ]\n"," [-2.31245    2.7736182]\n"," [ 2.7102613 -3.5756965]\n"," [-3.40954    4.090211 ]\n"," [ 2.6913376 -3.5021963]\n"," [ 2.6897116 -3.6117332]\n"," [-3.5783095  4.1871214]\n"," [-3.1177409  3.3090067]\n"," [-3.1523497  3.7392564]\n"," [-3.3056104  3.966416 ]\n"," [-2.286057   3.0201833]\n"," [-2.3931699  3.0152209]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.4136,  3.6401],\n","        [-2.2878,  2.9724],\n","        [-3.1063,  3.3651],\n","        [-3.4819,  3.7681],\n","        [-3.4899,  3.9987],\n","        [-3.6131,  4.1671],\n","        [-3.3625,  4.0748],\n","        [-3.2650,  3.9127],\n","        [-3.3866,  4.0292],\n","        [ 2.6236, -3.3636],\n","        [ 2.9724, -3.7994],\n","        [-3.4837,  4.1397],\n","        [-3.5368,  4.1239],\n","        [ 2.5423, -3.3727],\n","        [-3.3166,  3.8131],\n","        [-2.9238,  2.9620],\n","        [-3.4417,  4.0300],\n","        [-3.5325,  4.2055],\n","        [-3.2169,  3.8077],\n","        [-2.7682,  3.4647],\n","        [-3.5019,  4.1337],\n","        [-3.0419,  3.8491],\n","        [-3.3979,  3.4888],\n","        [-0.8638,  0.0882],\n","        [-3.6131,  4.0529],\n","        [-3.4135,  4.0095],\n","        [-3.6418,  4.0603],\n","        [-3.6682,  4.2150],\n","        [-3.5308,  3.8513],\n","        [-3.4792,  3.9222],\n","        [-3.3785,  3.9692],\n","        [-3.3385,  3.9939]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-3.4135933   3.640067  ]\n"," [-2.2877593   2.9724207 ]\n"," [-3.106282    3.3650656 ]\n"," [-3.481935    3.768101  ]\n"," [-3.489888    3.9987223 ]\n"," [-3.6130574   4.1671214 ]\n"," [-3.3624737   4.074795  ]\n"," [-3.265009    3.9126751 ]\n"," [-3.3866272   4.0291724 ]\n"," [ 2.6235516  -3.3636107 ]\n"," [ 2.9724112  -3.7993786 ]\n"," [-3.4836729   4.139715  ]\n"," [-3.5368216   4.123919  ]\n"," [ 2.54233    -3.3727152 ]\n"," [-3.3165913   3.8130968 ]\n"," [-2.9238346   2.9619813 ]\n"," [-3.441709    4.0299687 ]\n"," [-3.5324552   4.20554   ]\n"," [-3.216871    3.8077226 ]\n"," [-2.768214    3.4646587 ]\n"," [-3.5019038   4.1337385 ]\n"," [-3.0419364   3.8491337 ]\n"," [-3.3978734   3.4887834 ]\n"," [-0.8638078   0.08824626]\n"," [-3.6130917   4.0529428 ]\n"," [-3.4135137   4.0094695 ]\n"," [-3.6417527   4.0602555 ]\n"," [-3.668177    4.21501   ]\n"," [-3.5307648   3.8513064 ]\n"," [-3.47924     3.9222436 ]\n"," [-3.3785489   3.969237  ]\n"," [-3.3385158   3.9938636 ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0158, -0.3379],\n","        [-3.5207,  3.9305],\n","        [-3.2927,  3.8858],\n","        [-2.6015,  3.2092],\n","        [-3.1777,  3.5789],\n","        [-3.2373,  3.7233],\n","        [-2.5411,  2.7167],\n","        [-2.2950,  2.4881],\n","        [-3.5595,  3.9746],\n","        [-2.8519,  3.4268],\n","        [-0.5167,  0.7043],\n","        [-2.9573,  3.5979],\n","        [ 2.0145, -2.8399],\n","        [-3.2945,  3.7367],\n","        [-2.5372,  2.3010],\n","        [-1.8148,  2.1743],\n","        [-3.4135,  3.9266],\n","        [-2.7984,  3.0710],\n","        [ 1.5004, -2.2898],\n","        [-2.9393,  3.4610],\n","        [-3.1890,  3.8788],\n","        [-3.3599,  3.6699],\n","        [ 2.9498, -3.7540],\n","        [-1.9581,  2.1561],\n","        [ 2.7916, -3.6113],\n","        [-3.3797,  3.8838],\n","        [-3.1265,  3.8034],\n","        [-3.2897,  3.9856],\n","        [-3.4418,  4.1858],\n","        [-2.2606,  1.8373],\n","        [-1.1031,  0.9370],\n","        [-3.1788,  3.4344]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[ 0.01582766 -0.33792466]\n"," [-3.5207386   3.930483  ]\n"," [-3.2926767   3.8857582 ]\n"," [-2.6014574   3.2092474 ]\n"," [-3.177671    3.5788968 ]\n"," [-3.237309    3.723271  ]\n"," [-2.541144    2.7166593 ]\n"," [-2.2950149   2.488104  ]\n"," [-3.5595315   3.9745681 ]\n"," [-2.85185     3.426829  ]\n"," [-0.51672304  0.70428103]\n"," [-2.957319    3.597929  ]\n"," [ 2.0145006  -2.8398643 ]\n"," [-3.2944546   3.7366662 ]\n"," [-2.537231    2.3010008 ]\n"," [-1.814752    2.1743498 ]\n"," [-3.4135382   3.9266346 ]\n"," [-2.7983785   3.0709834 ]\n"," [ 1.5003723  -2.2897582 ]\n"," [-2.9392955   3.461008  ]\n"," [-3.1889503   3.8788304 ]\n"," [-3.3599284   3.6698534 ]\n"," [ 2.949766   -3.7539687 ]\n"," [-1.9580775   2.1560543 ]\n"," [ 2.791634   -3.6112986 ]\n"," [-3.3797214   3.8837793 ]\n"," [-3.126523    3.8034484 ]\n"," [-3.2896557   3.985626  ]\n"," [-3.4417593   4.1857796 ]\n"," [-2.2606432   1.8373026 ]\n"," [-1.1030847   0.9370448 ]\n"," [-3.1787868   3.4343534 ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.2146,  3.9765],\n","        [ 2.8985, -3.5664],\n","        [ 2.8682, -3.6252],\n","        [-3.4322,  4.0545],\n","        [-3.6786,  4.2495],\n","        [-2.9181,  3.6263],\n","        [-3.1928,  3.5985],\n","        [-2.9514,  3.6895],\n","        [-3.2382,  3.8437],\n","        [-3.3239,  3.9466],\n","        [ 2.9001, -3.6909],\n","        [-3.4750,  4.1436],\n","        [-2.3473,  3.1425],\n","        [-2.6599,  2.9173],\n","        [-3.4290,  4.1653],\n","        [ 0.1740, -0.2263],\n","        [-2.1137,  2.6193],\n","        [-3.5980,  4.2938],\n","        [-3.4069,  4.0969],\n","        [-1.6117,  1.8419],\n","        [-2.8689,  3.0194],\n","        [-3.4034,  4.1492],\n","        [-3.4524,  4.0167],\n","        [-3.5217,  4.1101],\n","        [-3.3404,  3.8670],\n","        [-2.8295,  3.5275],\n","        [-2.9632,  3.5463],\n","        [-3.3243,  3.9244],\n","        [-3.4038,  4.0926],\n","        [-3.4964,  4.1651],\n","        [-2.8478,  3.0824],\n","        [-3.4671,  4.0984]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-3.2146382   3.9764736 ]\n"," [ 2.8984916  -3.5663514 ]\n"," [ 2.868187   -3.625207  ]\n"," [-3.432171    4.054484  ]\n"," [-3.678625    4.2494874 ]\n"," [-2.9180691   3.626293  ]\n"," [-3.1928241   3.5984921 ]\n"," [-2.951379    3.6894705 ]\n"," [-3.2381647   3.8436654 ]\n"," [-3.3238924   3.9465823 ]\n"," [ 2.9001474  -3.6909027 ]\n"," [-3.4749818   4.143555  ]\n"," [-2.347338    3.1424596 ]\n"," [-2.6598508   2.9173265 ]\n"," [-3.4289749   4.165334  ]\n"," [ 0.17404382 -0.22629444]\n"," [-2.1137488   2.6192913 ]\n"," [-3.5980167   4.2938347 ]\n"," [-3.4069326   4.0969453 ]\n"," [-1.611746    1.8419142 ]\n"," [-2.868934    3.0194407 ]\n"," [-3.4034402   4.1491923 ]\n"," [-3.4524174   4.016688  ]\n"," [-3.521652    4.1101093 ]\n"," [-3.3404195   3.867011  ]\n"," [-2.8294897   3.5274782 ]\n"," [-2.9631798   3.546276  ]\n"," [-3.3242536   3.9243855 ]\n"," [-3.4037793   4.092627  ]\n"," [-3.4964387   4.165054  ]\n"," [-2.8477552   3.0824192 ]\n"," [-3.467101    4.098426  ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[ 2.7466, -3.6263],\n","        [-3.3749,  3.9467],\n","        [-2.5062,  3.0491],\n","        [-0.2581, -0.5937],\n","        [-3.4631,  4.1385],\n","        [-3.2177,  3.8571],\n","        [-3.4420,  4.0694],\n","        [-0.6759,  0.9141],\n","        [-1.8860,  2.2998],\n","        [-3.1100,  3.3561],\n","        [-2.5898,  3.0781],\n","        [-3.0263,  3.7290],\n","        [-3.1670,  3.8569],\n","        [-3.0185,  3.1166],\n","        [ 2.9802, -3.7872],\n","        [ 1.9814, -2.8927],\n","        [-3.1037,  3.4463],\n","        [-3.1266,  3.8879],\n","        [-3.4907,  4.2103],\n","        [-2.8945,  3.6266],\n","        [-2.1973,  2.8111],\n","        [-2.1616,  2.7887],\n","        [-2.5892,  3.3404],\n","        [ 2.9751, -3.7491],\n","        [-3.0478,  2.9948],\n","        [-3.3544,  3.8359],\n","        [-2.5737,  2.8467],\n","        [-2.7923,  3.4738],\n","        [-2.8998,  3.2338],\n","        [-2.9978,  3.4549],\n","        [-3.4631,  3.6159],\n","        [-0.6727,  0.5885]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[ 2.7466326  -3.6263022 ]\n"," [-3.3748732   3.946733  ]\n"," [-2.5062048   3.0490716 ]\n"," [-0.25806004 -0.5936681 ]\n"," [-3.4630842   4.1384788 ]\n"," [-3.2176983   3.8570557 ]\n"," [-3.4419503   4.069365  ]\n"," [-0.6759151   0.9140831 ]\n"," [-1.8859737   2.299817  ]\n"," [-3.1099727   3.3560574 ]\n"," [-2.5898135   3.078113  ]\n"," [-3.026274    3.728976  ]\n"," [-3.1669846   3.8569481 ]\n"," [-3.0185492   3.1165726 ]\n"," [ 2.9802096  -3.7872128 ]\n"," [ 1.9813654  -2.8927236 ]\n"," [-3.1036627   3.4463232 ]\n"," [-3.126636    3.8879356 ]\n"," [-3.4907272   4.210333  ]\n"," [-2.8944795   3.6266057 ]\n"," [-2.1973357   2.8111403 ]\n"," [-2.161599    2.7887104 ]\n"," [-2.589207    3.3404028 ]\n"," [ 2.9751     -3.7491405 ]\n"," [-3.047756    2.9947715 ]\n"," [-3.3543682   3.8358774 ]\n"," [-2.5736914   2.846719  ]\n"," [-2.792305    3.4737866 ]\n"," [-2.8998106   3.2338035 ]\n"," [-2.9978335   3.4548512 ]\n"," [-3.4630601   3.615872  ]\n"," [-0.6727261   0.5885491 ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-2.5409,  3.2753],\n","        [-3.0560,  3.6589],\n","        [-3.3460,  4.0877],\n","        [-3.4301,  4.0299],\n","        [-3.4115,  4.1099],\n","        [-2.7109,  3.2121],\n","        [-3.5467,  4.0183],\n","        [-3.3570,  4.0266],\n","        [-3.5540,  4.2203],\n","        [-3.5695,  4.1938],\n","        [-2.8350,  3.0118],\n","        [-2.2673,  2.5870],\n","        [-2.2990,  2.6948],\n","        [-3.0165,  3.6705],\n","        [ 0.1472, -1.0109],\n","        [-2.3980,  2.7801],\n","        [ 3.0285, -3.8117],\n","        [ 1.4173, -2.2198],\n","        [-2.9492,  3.6637],\n","        [-3.1553,  3.7808],\n","        [ 2.0107, -2.9876],\n","        [ 2.4370, -3.2586],\n","        [-3.1312,  3.8371],\n","        [-3.3087,  4.0392],\n","        [-3.5495,  4.2275],\n","        [-3.1544,  3.6476],\n","        [-3.1945,  3.8203],\n","        [-2.4397,  3.1578],\n","        [-2.6679,  2.9769],\n","        [-1.3900,  1.6792],\n","        [-2.5791,  3.2249],\n","        [-3.4442,  4.1331]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-2.5409112   3.2752917 ]\n"," [-3.0559642   3.6589456 ]\n"," [-3.3459592   4.0877333 ]\n"," [-3.4301429   4.0299015 ]\n"," [-3.4114718   4.1098986 ]\n"," [-2.7109492   3.212119  ]\n"," [-3.546673    4.018261  ]\n"," [-3.35701     4.0266275 ]\n"," [-3.5539517   4.220308  ]\n"," [-3.5694864   4.193805  ]\n"," [-2.8350239   3.011828  ]\n"," [-2.2672706   2.587004  ]\n"," [-2.2989724   2.6947725 ]\n"," [-3.0165231   3.6704693 ]\n"," [ 0.14717159 -1.0108848 ]\n"," [-2.3980234   2.7800665 ]\n"," [ 3.02852    -3.8117146 ]\n"," [ 1.4172906  -2.219761  ]\n"," [-2.9491737   3.663739  ]\n"," [-3.1553226   3.780793  ]\n"," [ 2.0107126  -2.9876382 ]\n"," [ 2.4370005  -3.2585888 ]\n"," [-3.1311808   3.8370776 ]\n"," [-3.308681    4.0391884 ]\n"," [-3.5494761   4.2274876 ]\n"," [-3.1543856   3.6476192 ]\n"," [-3.1945014   3.8202784 ]\n"," [-2.43965     3.1577568 ]\n"," [-2.6678715   2.9769285 ]\n"," [-1.3900064   1.6792269 ]\n"," [-2.5790892   3.2249174 ]\n"," [-3.444246    4.133127  ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.4588,  4.0861],\n","        [-3.2421,  3.7879],\n","        [ 2.8249, -3.6847],\n","        [ 1.8596, -2.6725],\n","        [ 1.1504, -2.0465],\n","        [ 3.0629, -3.8210],\n","        [-3.2833,  3.9912],\n","        [ 3.0147, -3.8350],\n","        [-3.6434,  4.2205],\n","        [ 2.9102, -3.7161],\n","        [-1.4167,  1.0135],\n","        [-3.5420,  4.0061],\n","        [ 2.8722, -3.6937],\n","        [-2.9013,  3.2945],\n","        [-1.3944,  0.9699],\n","        [-2.9285,  3.5918],\n","        [-3.0769,  3.1142],\n","        [-3.4129,  4.0279],\n","        [ 2.8169, -3.5821],\n","        [-3.3180,  3.7262],\n","        [-2.9917,  3.5471],\n","        [ 1.9313, -2.9586],\n","        [-3.3903,  3.9119],\n","        [ 2.6696, -3.5901],\n","        [ 2.2695, -3.2320],\n","        [-2.3721,  3.0428],\n","        [-2.7672,  3.3813],\n","        [ 1.4238, -2.1040],\n","        [-2.8215,  3.1502],\n","        [-2.7610,  3.2359],\n","        [ 2.7683, -3.5035],\n","        [-3.3856,  4.0185]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-3.4587505  4.086093 ]\n"," [-3.2420976  3.7878504]\n"," [ 2.8248503 -3.6846757]\n"," [ 1.8596283 -2.6725187]\n"," [ 1.1504391 -2.0464852]\n"," [ 3.0629387 -3.8210056]\n"," [-3.2833138  3.991223 ]\n"," [ 3.0147295 -3.8349633]\n"," [-3.643383   4.220516 ]\n"," [ 2.910237  -3.7160761]\n"," [-1.416663   1.0134518]\n"," [-3.541979   4.0060735]\n"," [ 2.872197  -3.693744 ]\n"," [-2.9013355  3.2945266]\n"," [-1.3944148  0.9699259]\n"," [-2.9285407  3.5918343]\n"," [-3.0768836  3.114225 ]\n"," [-3.4128938  4.0279455]\n"," [ 2.8169196 -3.5820673]\n"," [-3.3180194  3.7262383]\n"," [-2.991741   3.5470974]\n"," [ 1.931256  -2.9586186]\n"," [-3.3903456  3.911868 ]\n"," [ 2.6696317 -3.590122 ]\n"," [ 2.2695222 -3.2319949]\n"," [-2.3720746  3.0427918]\n"," [-2.767178   3.381304 ]\n"," [ 1.423758  -2.1039896]\n"," [-2.8214705  3.1502464]\n"," [-2.7609804  3.2358935]\n"," [ 2.768265  -3.5035086]\n"," [-3.3856108  4.018522 ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.1772,  3.6968],\n","        [-3.4868,  3.9623],\n","        [-3.6080,  4.1396],\n","        [-3.0573,  3.5179],\n","        [-2.1224,  2.5128],\n","        [-3.2413,  3.9066],\n","        [-3.4946,  4.1106],\n","        [-2.7499,  3.3739],\n","        [-0.0193, -0.1378],\n","        [-2.4745,  3.0825],\n","        [-3.4894,  4.0193],\n","        [ 1.4040, -1.6866],\n","        [ 1.3181, -2.2172],\n","        [-3.4196,  3.7136],\n","        [ 2.3466, -3.0984],\n","        [ 1.5969, -2.3978],\n","        [-3.0842,  3.2742],\n","        [ 2.6829, -3.6213],\n","        [-2.0839,  2.8184],\n","        [-3.1349,  3.8683],\n","        [-1.0274,  1.2249],\n","        [ 2.9340, -3.7849],\n","        [-2.4912,  2.9503],\n","        [ 0.6494, -0.8692],\n","        [ 2.5040, -3.3194],\n","        [-3.3543,  3.8864],\n","        [-3.5606,  4.1641],\n","        [ 1.3361, -2.1030],\n","        [-3.0988,  3.4365],\n","        [ 3.0241, -3.7631],\n","        [-3.0096,  3.0724],\n","        [-0.6520, -0.2723]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-3.1772444   3.6968198 ]\n"," [-3.4867792   3.9623358 ]\n"," [-3.608018    4.139575  ]\n"," [-3.0572553   3.5179002 ]\n"," [-2.1224074   2.5127938 ]\n"," [-3.241285    3.9065566 ]\n"," [-3.4945576   4.1105924 ]\n"," [-2.7498918   3.3738806 ]\n"," [-0.01925703 -0.13776983]\n"," [-2.474502    3.0824764 ]\n"," [-3.48941     4.0193396 ]\n"," [ 1.4040059  -1.686551  ]\n"," [ 1.3181493  -2.2171965 ]\n"," [-3.419572    3.7136123 ]\n"," [ 2.346603   -3.098373  ]\n"," [ 1.596914   -2.397793  ]\n"," [-3.0842326   3.2742167 ]\n"," [ 2.682937   -3.621284  ]\n"," [-2.0839038   2.8183606 ]\n"," [-3.134905    3.8683007 ]\n"," [-1.0274231   1.2248621 ]\n"," [ 2.933971   -3.784946  ]\n"," [-2.491164    2.9502876 ]\n"," [ 0.64936775 -0.86919653]\n"," [ 2.5040147  -3.319379  ]\n"," [-3.3542974   3.8864036 ]\n"," [-3.5605633   4.1640596 ]\n"," [ 1.3361056  -2.1030157 ]\n"," [-3.0988123   3.4364562 ]\n"," [ 3.0240755  -3.7631133 ]\n"," [-3.0095549   3.0723593 ]\n"," [-0.6519885  -0.2723345 ]]\n","SequenceClassifierOutput(loss=None, logits=tensor([[-3.1748,  3.5725],\n","        [-3.0409,  3.7325],\n","        [-3.3931,  4.0003],\n","        [-2.1653,  2.2156],\n","        [-2.7907,  3.1412],\n","        [-3.2776,  3.9268],\n","        [-2.6705,  3.2611],\n","        [ 2.4122, -3.3139],\n","        [-2.2695,  2.8072],\n","        [ 3.0123, -3.6895],\n","        [ 2.5107, -3.2876],\n","        [-0.4376,  0.7813],\n","        [-1.4642,  2.0099],\n","        [ 1.9353, -2.7793],\n","        [ 0.6788, -1.4380]], device='cuda:0'), hidden_states=None, attentions=None)\n","[[-3.1747763   3.5724967 ]\n"," [-3.0409415   3.7324567 ]\n"," [-3.3931208   4.0002694 ]\n"," [-2.1653116   2.2155964 ]\n"," [-2.790663    3.1411998 ]\n"," [-3.2775714   3.9268014 ]\n"," [-2.6705337   3.2611084 ]\n"," [ 2.4122138  -3.313884  ]\n"," [-2.2695124   2.8072479 ]\n"," [ 3.0122793  -3.689467  ]\n"," [ 2.5106683  -3.2875943 ]\n"," [-0.43759537  0.7813253 ]\n"," [-1.46418     2.009871  ]\n"," [ 1.9353417  -2.7793062 ]\n"," [ 0.6787886  -1.4380132 ]]\n","17\n","Accuracy : 0.841421568627451\n","Test loss: 0.0\n","Test testing took 0:00:04 time\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15BituVZxZtJ","executionInfo":{"status":"ok","timestamp":1638824210582,"user_tz":-330,"elapsed":523,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"6f0aef95-687d-49b3-da63-e3ce8b9d659c"},"source":["# Accuracy on the CoLA benchmark is measured using the \"Matthews correlation coefficient\" (MCC). This is the metric used by the wider NLP community to evaluate performance on CoLA.\n","# With this metric, +1 is the best score, and -1 is the worst score.\n","\n","from sklearn.metrics import matthews_corrcoef\n","\n","matthews_set = []\n","\n","# Evaluate each test bat5ch using Matthews correlation coefficient\n","\n","for i in range(len(true_labels)):\n","\n","  # The predictions for this batch are a 2-column ndarray (one column for \"0\" and one column for \"1\"). Pick the label with the highest value and turn this in to a list of 0s and 1s\n","  # print('predictions[i]')\n","  # print(predictions[i])\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  # print('pred_labels_i')\n","  # print(pred_labels_i)\n","  # Calculate and store the coef for this batch\n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n","  matthews_set.append(matthews)\n","\n","matthews_set"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.4472135954999579,\n"," 0.731126155013931,\n"," 0.5633234713140696,\n"," 0.3567530340063379,\n"," 0.9229582069908973,\n"," 0.5807564950208268,\n"," 0.6457765999379483,\n"," 0.777878154009821,\n"," 0.44761904761904764,\n"," 0.394853422012197,\n"," 0.3478327964999673,\n"," 0.7867957924694432,\n"," 0.6180700462007377,\n"," 0.8958064164776167,\n"," 0.6813969328454993,\n"," 0.4458874458874459,\n"," 0.7]"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"uH8rURjY-rWS","executionInfo":{"status":"ok","timestamp":1638824217376,"user_tz":-330,"elapsed":970,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"49ea806d-c657-4f25-9967-ca69ad9ea43e"},"source":["# Create a barplot showing the MCC score for each batch of test samples.\n","ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n","\n","plt.title('MCC Score per Batch')\n","plt.ylabel('MCC Score (-1 to +1)')\n","plt.xlabel('Batch #')\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tUw4mdE_6zm","executionInfo":{"status":"ok","timestamp":1638824224727,"user_tz":-330,"elapsed":505,"user":{"displayName":"Shweta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giq5_h50AUuKg6-B711cwbRxwkwycz5EMbKCcqyiA=s64","userId":"05242245977803223502"}},"outputId":"81cb70c8-af1d-4805-f628-5aacd64ad648"},"source":["flat_predictions = np.concatenate(predictions, axis=0)\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n","\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","print('Total MCC: ', mcc)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total MCC:  0.6088909077241057\n"]}]}]}